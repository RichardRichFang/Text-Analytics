{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egp-LkXKsa8c"
   },
   "source": [
    "# **Amazon: Reviews (Sports and Outdoors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QM809fedsPKT"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "import re, random, os\n",
    "import string, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# spacy for basic preprocessing, optional, can use nltk as well (lemmatisation etc.)\n",
    "# import spacy\n",
    "\n",
    "# gensim for LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "#from pyLDAvis import gensim_models as pg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QqwjvakHsPKV"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Sports_and_Outdoors_5.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(df, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mgetDF\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSports_and_Outdoors_5.json.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mgetDF\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     12\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m parse(path):\n\u001b[1;32m     15\u001b[0m   df[i] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m     16\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(path):\n\u001b[0;32m----> 7\u001b[0m   g \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSports_and_Outdoors_5.json.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m g:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(l)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Sports_and_Outdoors_5.json.gz'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = ('Sports_and_Outdoors_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBiS6WV0sPKV",
    "outputId": "2fbf49e6-d082-4daf-c16b-a9b82645d60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   overall  verified  reviewTime      reviewerID        asin reviewerName  \\\n",
      "0      5.0      True  06 3, 2015  A180LQZBUWVOLF  0000032034   Michelle A   \n",
      "1      1.0      True  04 1, 2015   ATMFGKU5SVEYY  0000032034    Crystal R   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0            What a spectacular tutu! Very slimming.   \n",
      "1  What the heck? Is this a tutu for nuns? I know...   \n",
      "\n",
      "                     summary  unixReviewTime style vote image  \n",
      "0                 Five Stars      1433289600   NaN  NaN   NaN  \n",
      "1  Is this a tutu for nuns?!      1427846400   NaN  NaN   NaN  \n",
      "2839940\n",
      "Unique Products\n",
      "104687\n",
      "Unique Users\n",
      "332447\n"
     ]
    }
   ],
   "source": [
    "print(data.head(2))\n",
    "print(len(data))\n",
    "print('Unique Products')\n",
    "print(len(data.groupby('asin')))\n",
    "print('Unique Users')\n",
    "print(len(data.groupby('reviewerID')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sgIZZjbsPKV"
   },
   "source": [
    "# Preprocessing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeTWbVxHsPKW",
    "outputId": "be914998-a00a-4740-e85f-59b38de54952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                 0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "reviewerName          279\n",
       "reviewText           1114\n",
       "summary               611\n",
       "unixReviewTime          0\n",
       "style             1242772\n",
       "vote              2461060\n",
       "image             2775405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a copy\n",
    "process_reviews=data.copy()\n",
    "\n",
    "## Checking for null values\n",
    "process_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o2kz0ZqsPKW"
   },
   "outputs": [],
   "source": [
    "## Clear NAs in reviewText\n",
    "process_reviews['reviewText']=process_reviews['reviewText'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uL79NBRsPKW"
   },
   "outputs": [],
   "source": [
    "## Combine review text and summary column\n",
    "process_reviews['reviews']=process_reviews['reviewText']+process_reviews['summary']\n",
    "process_reviews=process_reviews.drop(['reviewText', 'summary'], axis=1)\n",
    "process_reviews = process_reviews.drop(columns=['style', 'vote', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su4pN51dsPKX",
    "outputId": "e4f4b170-8e21-49b3-f862-f0c61da3f2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1921398\n",
       "4.0     495533\n",
       "3.0     210215\n",
       "1.0     111157\n",
       "2.0     101637\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Figuring out the distribution of categories\n",
    "process_reviews['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RULVpaPRsPKX",
    "outputId": "bbc382e0-342c-4613-a5cc-7af9e20430f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2015</td>\n",
       "      <td>A180LQZBUWVOLF</td>\n",
       "      <td>0000032034</td>\n",
       "      <td>Michelle A</td>\n",
       "      <td>1433289600</td>\n",
       "      <td>What a spectacular tutu! Very slimming.Five Stars</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 1, 2015</td>\n",
       "      <td>ATMFGKU5SVEYY</td>\n",
       "      <td>0000032034</td>\n",
       "      <td>Crystal R</td>\n",
       "      <td>1427846400</td>\n",
       "      <td>What the heck? Is this a tutu for nuns? I know...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 13, 2015</td>\n",
       "      <td>A1QE70QBJ8U6ZG</td>\n",
       "      <td>0000032034</td>\n",
       "      <td>darla Landreth</td>\n",
       "      <td>1421107200</td>\n",
       "      <td>Exactly what we were looking for!Five Stars</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 23, 2014</td>\n",
       "      <td>A22CP6Z73MZTYU</td>\n",
       "      <td>0000032034</td>\n",
       "      <td>L. Huynh</td>\n",
       "      <td>1419292800</td>\n",
       "      <td>I used this skirt for a Halloween costume and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 15, 2014</td>\n",
       "      <td>A22L28G8NRNLLN</td>\n",
       "      <td>0000032034</td>\n",
       "      <td>McKenna</td>\n",
       "      <td>1418601600</td>\n",
       "      <td>This is thick enough that you can't see throug...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin    reviewerName  \\\n",
       "0      5.0      True   06 3, 2015  A180LQZBUWVOLF  0000032034      Michelle A   \n",
       "1      1.0      True   04 1, 2015   ATMFGKU5SVEYY  0000032034       Crystal R   \n",
       "2      5.0      True  01 13, 2015  A1QE70QBJ8U6ZG  0000032034  darla Landreth   \n",
       "3      5.0      True  12 23, 2014  A22CP6Z73MZTYU  0000032034        L. Huynh   \n",
       "4      4.0      True  12 15, 2014  A22L28G8NRNLLN  0000032034         McKenna   \n",
       "\n",
       "   unixReviewTime                                            reviews Sentiment  \n",
       "0      1433289600  What a spectacular tutu! Very slimming.Five Stars  Positive  \n",
       "1      1427846400  What the heck? Is this a tutu for nuns? I know...  Negative  \n",
       "2      1421107200        Exactly what we were looking for!Five Stars  Positive  \n",
       "3      1419292800  I used this skirt for a Halloween costume and ...  Positive  \n",
       "4      1418601600  This is thick enough that you can't see throug...  Positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(row):\n",
    "    if row['overall']== 3.0:\n",
    "        val = 'Neutral'\n",
    "    elif row['overall']==1.0 or row['overall']==2.0:\n",
    "        val = 'Negative'\n",
    "    elif row['overall'] ==4.0 or row['overall']==5.0:\n",
    "        val = 'Positive'\n",
    "    else:\n",
    "        val = -1\n",
    "    return val\n",
    "\n",
    "process_reviews['Sentiment'] = process_reviews.apply(f, axis = 1)\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvp2dXzEsPKX"
   },
   "outputs": [],
   "source": [
    "## New data frame which has date and year\n",
    "new = process_reviews[\"reviewTime\"].str.split(\",\", n = 1, expand = True)\n",
    "\n",
    "## Separate date column from new data frame\n",
    "process_reviews[\"date\"]= new[0]\n",
    "\n",
    "## Separate year column from new data frame\n",
    "process_reviews[\"year\"]= new[1]\n",
    "process_reviews=process_reviews.drop(['reviewTime'], axis=1)\n",
    "\n",
    "## Splitting the date\n",
    "new1 = process_reviews[\"date\"].str.split(\" \", n = 1, expand = True)\n",
    "\n",
    "## Adding month to the main dataset\n",
    "process_reviews[\"month\"]= new1[0]\n",
    "\n",
    "## Adding day to the main dataset\n",
    "process_reviews[\"day\"]= new1[1]\n",
    "process_reviews=process_reviews.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB7rAtwXsPKX"
   },
   "outputs": [],
   "source": [
    "## Removing unnecessary columns\n",
    "process_reviews=process_reviews.drop(['reviewerName','unixReviewTime','reviewerID','asin'], axis=1)\n",
    "\n",
    "## Creating a copy\n",
    "clean_reviews=process_reviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoasqpphsPKX",
    "outputId": "97708b9b-2e10-42c0-f7f2-03485f9a870a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>what a spectacular tutu very slimmingfive stars</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2015</td>\n",
       "      <td>06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>what the heck is this a tutu for nuns i know y...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2015</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>exactly what we were looking forfive stars</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i used this skirt for a halloween costume and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>this is thick enough that you cant see through...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified                                            reviews  \\\n",
       "0      5.0      True    what a spectacular tutu very slimmingfive stars   \n",
       "1      1.0      True  what the heck is this a tutu for nuns i know y...   \n",
       "2      5.0      True         exactly what we were looking forfive stars   \n",
       "3      5.0      True  i used this skirt for a halloween costume and ...   \n",
       "4      4.0      True  this is thick enough that you cant see through...   \n",
       "\n",
       "  Sentiment   year month day  \n",
       "0  Positive   2015    06   3  \n",
       "1  Negative   2015    04   1  \n",
       "2  Positive   2015    01  13  \n",
       "3  Positive   2014    12  23  \n",
       "4  Positive   2014    12  15  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def review_cleaning(text):\n",
    "\n",
    "    text = str(text).lower() # lowercase text\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove links\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\n', '', text) # remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "process_reviews['reviews']=process_reviews['reviews'].apply(lambda x:review_cleaning(x))\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RxDFFuCsPKY",
    "outputId": "696b34e4-12e0-4e0a-cc64-ef54ac6d0a51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jiaotianyu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hG_ctYPDsPKY"
   },
   "outputs": [],
   "source": [
    "## Remove all the stop words in the review column\n",
    "stop_words= ['yourselves', 'between', 'whom', 'itself', 'is', \"she's\", 'up', 'herself', 'here', 'your', 'each',\n",
    "             'we', 'he', 'my', \"you've\", 'having', 'in', 'both', 'for', 'themselves', 'are', 'them', 'other',\n",
    "             'and', 'an', 'during', 'their', 'can', 'yourself', 'she', 'until', 'so', 'these', 'ours', 'above',\n",
    "             'what', 'while', 'have', 're', 'more', 'only', \"needn't\", 'when', 'just', 'that', 'were', \"don't\",\n",
    "             'very', 'should', 'any', 'y', 'isn', 'who',  'a', 'they', 'to', 'too', \"should've\", 'has', 'before',\n",
    "             'into', 'yours', \"it's\", 'do', 'against', 'on',  'now', 'her', 've', 'd', 'by', 'am', 'from',\n",
    "             'about', 'further', \"that'll\", \"you'd\", 'you', 'as', 'how', 'been', 'the', 'or', 'doing', 'such',\n",
    "             'his', 'himself', 'ourselves',  'was', 'through', 'out', 'below', 'own', 'myself', 'theirs',\n",
    "             'me', 'why', 'once',  'him', 'than', 'be', 'most', \"you'll\", 'same', 'some', 'with', 'few', 'it',\n",
    "             'at', 'after', 'its', 'which', 'there','our', 'this', 'hers', 'being', 'did', 'of', 'had', 'under',\n",
    "             'over','again', 'where', 'those', 'then', \"you're\", 'i', 'because', 'does', 'all']\n",
    "\n",
    "process_reviews['reviews'] = process_reviews['reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToqmpuGLsPKY"
   },
   "source": [
    "# Plotting some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygSwhIS1sPKY"
   },
   "outputs": [],
   "source": [
    "## Year vs Sentiment count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "process_reviews.groupby(['year', 'sentiment'])['sentiment'].count().unstack().plot(legend=True, ax=ax)\n",
    "ax.set_title('Year vs Sentiment count')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Sentiment count')\n",
    "plt.savefig('plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV5_3UW6sPKY"
   },
   "outputs": [],
   "source": [
    "## Review Rating Distribution\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "data = [go.Histogram(x=process_reviews['overall'])]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Review Rating Distribution',\n",
    "    xaxis=dict(title='Rating'),\n",
    "    yaxis=dict(title='Count'),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "pyo.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0wrntzusPKY"
   },
   "outputs": [],
   "source": [
    "## Filtering data\n",
    "\n",
    "review_pos = process_reviews[process_reviews[\"sentiment\"]=='Positive'].dropna()\n",
    "review_neg = process_reviews[process_reviews[\"sentiment\"]=='Negative'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg32zZqqsPKY"
   },
   "outputs": [],
   "source": [
    "## Wordcloud-Positive reviews\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "text = review_pos[\"reviews\"]\n",
    "wordcloud = WordCloud(\n",
    "    width = 1000,\n",
    "    height = 500,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(text))\n",
    "fig = plt.figure(\n",
    "    figsize = (40, 30),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPljmPAlsPKY"
   },
   "outputs": [],
   "source": [
    "## Wordcloud-Negative reviews\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "text = review_neg[\"reviews\"]\n",
    "wordcloud = WordCloud(\n",
    "    width = 1000,\n",
    "    height = 500,\n",
    "    background_color = 'black',\n",
    "    stopwords = stop_words).generate(str(text))\n",
    "fig = plt.figure(\n",
    "    figsize = (40, 30),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysuhwHDgsPKY"
   },
   "outputs": [],
   "source": [
    "## Bigram analysis\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "%matplotlib inline\n",
    "\n",
    "def horizontal_bar_chart(df, color):\n",
    "    trace = go.Bar(\n",
    "        y=df[\"word\"][::-1],\n",
    "        x=df[\"wordcount\"][::-1],\n",
    "        showlegend=False,\n",
    "        orientation = 'h',\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "        ),\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "## Custom function for ngram generation\n",
    "def generate_ngrams(text, n_gram=1):\n",
    "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
    "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "## Get the bar chart from positive reviews\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in review_pos[\"reviews\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n",
    "\n",
    "## Get the bar chart from negative reviews\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in review_neg[\"reviews\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace2 = horizontal_bar_chart(fd_sorted.head(25), 'blue')\n",
    "\n",
    "## Creating two subplots\n",
    "fig = make_subplots(rows=2, cols=1, vertical_spacing=0.04,horizontal_spacing=0.25,\n",
    "                          subplot_titles=[\"Bigram plots of Positive reviews\",\n",
    "                                          \"Bigram plots of Negative reviews\"\n",
    "                                          ])\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "\n",
    "## Plotting the graphs\n",
    "fig['layout'].update(height=1000, width=800, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Plots\")\n",
    "iplot(fig, filename='word-plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9dg-ZhTsPKY"
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8QidFGLsPKZ",
    "outputId": "37946fd3-2cf5-40db-eeba-c2148f9a3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------process_reviewsset --------\n",
      "5.0    1921398\n",
      "4.0     495533\n",
      "3.0     210215\n",
      "1.0     111157\n",
      "2.0     101637\n",
      "Name: overall, dtype: int64\n",
      "2839940\n",
      "-------------------------\n",
      "No of Short reviews\n",
      "1498634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_reviews['Num_words_text'] = process_reviews['reviews'].apply(lambda x:len(str(x).split()))\n",
    "print('-------process_reviewsset --------')\n",
    "print(process_reviews['overall'].value_counts())\n",
    "print(len(process_reviews))\n",
    "print('-------------------------')\n",
    "max_review_process_reviews_sentence_length  = process_reviews['Num_words_text'].max()\n",
    "\n",
    "mask = (process_reviews['Num_words_text'] < 100) & (process_reviews['Num_words_text'] >15)\n",
    "process_reviews_short_reviews = process_reviews[mask]\n",
    "process_reviews_sampled = process_reviews_short_reviews.groupby('overall').apply(lambda x: x.sample(n=20000)).reset_index(drop = True)\n",
    "\n",
    "print('No of Short reviews')\n",
    "print(len(process_reviews_short_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTHcdD4OsPKZ",
    "outputId": "b1430c3d-bef2-4216-b858-71d48ef7bcda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Num_words_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>what the heck is this a tutu for nuns i know y...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2015</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i used this skirt for a halloween costume and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>this is thick enough that you cant see through...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>more of a road map than a useful topographical...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>comprehensive atlas very happy with how much d...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2016</td>\n",
       "      <td>08</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified                                            reviews  \\\n",
       "1      1.0      True  what the heck is this a tutu for nuns i know y...   \n",
       "3      5.0      True  i used this skirt for a halloween costume and ...   \n",
       "4      4.0      True  this is thick enough that you cant see through...   \n",
       "8      3.0      True  more of a road map than a useful topographical...   \n",
       "9      5.0      True  comprehensive atlas very happy with how much d...   \n",
       "\n",
       "  Sentiment   year month day  Num_words_text  \n",
       "1  Negative   2015    04   1              44  \n",
       "3  Positive   2014    12  23              92  \n",
       "4  Positive   2014    12  15              37  \n",
       "8   Neutral   2016    12  12              45  \n",
       "9  Positive   2016    08  13              39  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_reviews_short_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ds5gmUy5sPKZ"
   },
   "outputs": [],
   "source": [
    "process_reviews_short_reviews.to_csv('process_reviews_short_reviews.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2Rmk_FasPKZ",
    "outputId": "087db929-0691-421b-dec9-2dbd403bd19b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Num_words_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>what the heck is this a tutu for nuns i know y...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2015</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i used this skirt for a halloween costume and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>this is thick enough that you cant see through...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>more of a road map than a useful topographical...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>comprehensive atlas very happy with how much d...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2016</td>\n",
       "      <td>08</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified                                            reviews  \\\n",
       "1      1.0      True  what the heck is this a tutu for nuns i know y...   \n",
       "3      5.0      True  i used this skirt for a halloween costume and ...   \n",
       "4      4.0      True  this is thick enough that you cant see through...   \n",
       "8      3.0      True  more of a road map than a useful topographical...   \n",
       "9      5.0      True  comprehensive atlas very happy with how much d...   \n",
       "\n",
       "  Sentiment   year month day  Num_words_text  \n",
       "1  Negative   2015    04   1              44  \n",
       "3  Positive   2014    12  23              92  \n",
       "4  Positive   2014    12  15              37  \n",
       "8   Neutral   2016    12  12              45  \n",
       "9  Positive   2016    08  13              39  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_reviews_short_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPcPUkf-sPKZ",
    "outputId": "b9d2b092-abf6-4574-a124-7b0786d69a27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/ipykernel_4730/3003630042.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  process_reviews_short_reviews['year'] = pd.to_datetime(process_reviews_short_reviews['year'])\n"
     ]
    }
   ],
   "source": [
    "process_reviews_short_reviews['year'] = pd.to_datetime(process_reviews_short_reviews['year'])\n",
    "before = process_reviews_short_reviews[process_reviews_short_reviews['year'] < '2012']\n",
    "after = process_reviews_short_reviews[(process_reviews_short_reviews['year'] > '2013') & (process_reviews_short_reviews['year'] < '2015')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EshlTVaDsPKZ",
    "outputId": "4b7375d2-6c03-4e8c-f203-f1e81767902a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Num_words_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>arizona is a spectacular state  there is so mu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>09</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>waste of money in my opinion  fails to show im...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>05</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i have already made great use of this gazeteer...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>02</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>ok  i am new to the world of fly fishing  but ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>08</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>these bands are high quality and very easy to ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>03</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     overall  verified                                            reviews  \\\n",
       "27       5.0      True  arizona is a spectacular state  there is so mu...   \n",
       "67       1.0      True  waste of money in my opinion  fails to show im...   \n",
       "68       5.0      True  i have already made great use of this gazeteer...   \n",
       "70       5.0     False  ok  i am new to the world of fly fishing  but ...   \n",
       "119      4.0      True  these bands are high quality and very easy to ...   \n",
       "\n",
       "    Sentiment       year month day  Num_words_text  \n",
       "27   Positive 2008-01-01    09   6              64  \n",
       "67   Negative 2010-01-01    05  18              16  \n",
       "68   Positive 2010-01-01    02   6              42  \n",
       "70   Positive 2008-01-01    08   8              63  \n",
       "119  Positive 2011-01-01    03  25              43  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpKZpZ4qsPKZ",
    "outputId": "d86f0834-283d-431a-db23-3ae1a2532d86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Num_words_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i used this skirt for a halloween costume and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>this is thick enough that you cant see through...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>these gazetters are amazing i own them for ny ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i have several of these they all have proven v...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>04</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>i hunt and fish in arizona and i need a map th...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>03</td>\n",
       "      <td>21</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall  verified                                            reviews  \\\n",
       "3       5.0      True  i used this skirt for a halloween costume and ...   \n",
       "4       4.0      True  this is thick enough that you cant see through...   \n",
       "25      5.0      True  these gazetters are amazing i own them for ny ...   \n",
       "60      4.0      True  i have several of these they all have proven v...   \n",
       "61      5.0      True  i hunt and fish in arizona and i need a map th...   \n",
       "\n",
       "   Sentiment       year month day  Num_words_text  \n",
       "3   Positive 2014-01-01    12  23              92  \n",
       "4   Positive 2014-01-01    12  15              37  \n",
       "25  Positive 2014-01-01    11   9              80  \n",
       "60  Positive 2014-01-01    04  13              23  \n",
       "61  Positive 2014-01-01    03  21              69  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA9-prtbsPKZ"
   },
   "outputs": [],
   "source": [
    "## Before 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt01xuazsPKZ",
    "outputId": "1b6215b9-797e-439e-e8b4-84e9fcfb41c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/ipykernel_4730/574739543.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  before['reviews']=before['reviews'].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "# before 2012\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    textArr = text.split(' ')\n",
    "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "before['reviews']=before['reviews'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCqzJVV-sPKZ"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']):\n",
    "       output = []\n",
    "       for sent in texts:\n",
    "                doc = nlp(sent)\n",
    "                output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4HQbYefsPKZ",
    "outputId": "9ba115af-6e51-4633-d173-6a5a907d41ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waste money opinion  fails show important mountains ridges terraindisapointing detail\n",
      "['money', 'opinion', 'important', 'mountain', 'ridge', 'detail']\n"
     ]
    }
   ],
   "source": [
    "text_list=before['reviews'].tolist()\n",
    "print(text_list[1])\n",
    "tokenized_reviews = lemmatization(text_list)\n",
    "print(tokenized_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dq4cbkrcsPKZ"
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4cCvUE7sPKZ"
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=10,\n",
    "                random_state=100,\n",
    "                chunksize=1000,\n",
    "                passes=50,\n",
    "                iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqLWYyJpsPKZ",
    "outputId": "82847b39-85af-40b6-a1d6-1ef87c339952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.058*\"good\" + 0.044*\"great\" + 0.041*\"price\" + 0.037*\"quality\" + 0.035*\"product\" + 0.017*\"gun\" + 0.016*\"case\" + 0.012*\"high\" + 0.011*\"nice\" + 0.011*\"money\"'),\n",
       " (1,\n",
       "  '0.153*\"light\" + 0.036*\"battery\" + 0.036*\"bright\" + 0.026*\"tent\" + 0.023*\"road\" + 0.018*\"chain\" + 0.018*\"basket\" + 0.018*\"helmet\" + 0.013*\"leak\" + 0.011*\"dark\"'),\n",
       " (2,\n",
       "  '0.033*\"great\" + 0.025*\"time\" + 0.022*\"good\" + 0.019*\"product\" + 0.018*\"year\" + 0.015*\"use\" + 0.014*\"easy\" + 0.012*\"old\" + 0.012*\"day\" + 0.010*\"last\"'),\n",
       " (3,\n",
       "  '0.034*\"short\" + 0.021*\"sight\" + 0.017*\"pad\" + 0.016*\"comfortable\" + 0.013*\"front\" + 0.011*\"scope\" + 0.011*\"ring\" + 0.011*\"padding\" + 0.010*\"little\" + 0.010*\"mat\"'),\n",
       " (4,\n",
       "  '0.029*\"band\" + 0.027*\"tool\" + 0.019*\"great\" + 0.018*\"easy\" + 0.018*\"use\" + 0.017*\"workout\" + 0.017*\"kit\" + 0.017*\"wrist\" + 0.016*\"work\" + 0.016*\"product\"'),\n",
       " (5,\n",
       "  '0.094*\"bike\" + 0.028*\"tire\" + 0.021*\"easy\" + 0.021*\"ride\" + 0.020*\"bar\" + 0.017*\"mile\" + 0.016*\"seat\" + 0.015*\"great\" + 0.014*\"tube\" + 0.012*\"mountain\"'),\n",
       " (6,\n",
       "  '0.096*\"knife\" + 0.028*\"blade\" + 0.023*\"sharp\" + 0.019*\"steel\" + 0.017*\"belt\" + 0.016*\"cap\" + 0.015*\"good\" + 0.014*\"nice\" + 0.013*\"great\" + 0.013*\"sheath\"'),\n",
       " (7,\n",
       "  '0.053*\"size\" + 0.047*\"small\" + 0.033*\"large\" + 0.027*\"big\" + 0.022*\"strap\" + 0.020*\"ball\" + 0.018*\"little\" + 0.017*\"nice\" + 0.017*\"fit\" + 0.013*\"heavy\"'),\n",
       " (8,\n",
       "  '0.034*\"comfortable\" + 0.033*\"grip\" + 0.032*\"hand\" + 0.030*\"glove\" + 0.026*\"fit\" + 0.023*\"holster\" + 0.022*\"pair\" + 0.020*\"good\" + 0.020*\"great\" + 0.017*\"goggle\"'),\n",
       " (9,\n",
       "  '0.068*\"bag\" + 0.053*\"water\" + 0.045*\"bottle\" + 0.018*\"pack\" + 0.018*\"great\" + 0.015*\"cold\" + 0.012*\"hot\" + 0.011*\"lock\" + 0.011*\"dry\" + 0.011*\"warm\"')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWDMwhjEsPKZ"
   },
   "outputs": [],
   "source": [
    "## 2013 - 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO3gbGSmsPKZ",
    "outputId": "fbd3a280-c8af-4821-f4a1-62508c878742"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/ipykernel_4730/3818064874.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after['reviews']=after['reviews'].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    textArr = text.split(' ')\n",
    "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "after['reviews']=after['reviews'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q90DD1RNsPKa"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']):\n",
    "       output = []\n",
    "       for sent in texts:\n",
    "                doc = nlp(sent)\n",
    "                output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82N7uitcsPKa",
    "outputId": "7c0e6b1f-c86e-4697-9d16-4a71b0703263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thick enough cant see long sure check dimensions ended cutting shorterthis thick enough cant see \n",
      "['thick', 'long', 'sure', 'check', 'dimension', 'thick']\n"
     ]
    }
   ],
   "source": [
    "text_list=after['reviews'].tolist()\n",
    "print(text_list[1])\n",
    "tokenized_reviews = lemmatization(text_list)\n",
    "print(tokenized_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut2xJo1_sPKa"
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qFUneYCsPKa"
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=10,\n",
    "                random_state=100,\n",
    "                chunksize=1000,\n",
    "                passes=50,\n",
    "                iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJcJmWVGsPKa",
    "outputId": "d4df303d-ef70-45b0-d834-49737dd9456a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.071*\"knife\" + 0.038*\"glove\" + 0.038*\"gun\" + 0.034*\"ball\" + 0.028*\"hand\" + 0.024*\"sharp\" + 0.023*\"blade\" + 0.022*\"good\" + 0.019*\"belt\" + 0.018*\"great\"'),\n",
       " (1,\n",
       "  '0.066*\"size\" + 0.064*\"fit\" + 0.043*\"small\" + 0.033*\"large\" + 0.027*\"short\" + 0.026*\"comfortable\" + 0.024*\"nice\" + 0.022*\"big\" + 0.021*\"perfect\" + 0.020*\"tight\"'),\n",
       " (2,\n",
       "  '0.047*\"bright\" + 0.035*\"sight\" + 0.032*\"shirt\" + 0.025*\"shoe\" + 0.022*\"kid\" + 0.019*\"cover\" + 0.017*\"replacement\" + 0.017*\"rifle\" + 0.017*\"front\" + 0.015*\"arrow\"'),\n",
       " (3,\n",
       "  '0.030*\"warm\" + 0.028*\"time\" + 0.019*\"band\" + 0.019*\"battery\" + 0.015*\"cap\" + 0.013*\"first\" + 0.013*\"tube\" + 0.012*\"week\" + 0.012*\"lightweight\" + 0.012*\"towel\"'),\n",
       " (4,\n",
       "  '0.031*\"water\" + 0.029*\"year\" + 0.026*\"great\" + 0.026*\"bottle\" + 0.024*\"old\" + 0.014*\"good\" + 0.013*\"time\" + 0.012*\"target\" + 0.011*\"use\" + 0.011*\"son\"'),\n",
       " (5,\n",
       "  '0.086*\"good\" + 0.064*\"price\" + 0.064*\"quality\" + 0.048*\"great\" + 0.041*\"star\" + 0.026*\"money\" + 0.022*\"grip\" + 0.018*\"high\" + 0.017*\"nice\" + 0.015*\"cheap\"'),\n",
       " (6,\n",
       "  '0.080*\"bag\" + 0.037*\"case\" + 0.029*\"tool\" + 0.021*\"stuff\" + 0.020*\"great\" + 0.018*\"kit\" + 0.017*\"heavy\" + 0.014*\"pad\" + 0.012*\"handy\" + 0.012*\"room\"'),\n",
       " (7,\n",
       "  '0.119*\"product\" + 0.067*\"great\" + 0.041*\"good\" + 0.031*\"quality\" + 0.024*\"sock\" + 0.020*\"value\" + 0.018*\"gift\" + 0.017*\"price\" + 0.016*\"slipper\" + 0.015*\"husband\"'),\n",
       " (8,\n",
       "  '0.062*\"bike\" + 0.040*\"light\" + 0.024*\"great\" + 0.022*\"cool\" + 0.017*\"ride\" + 0.016*\"day\" + 0.016*\"cold\" + 0.014*\"night\" + 0.013*\"tire\" + 0.013*\"hot\"'),\n",
       " (9,\n",
       "  '0.028*\"light\" + 0.027*\"great\" + 0.024*\"easy\" + 0.020*\"use\" + 0.019*\"good\" + 0.016*\"weight\" + 0.015*\"little\" + 0.014*\"strap\" + 0.014*\"nice\" + 0.012*\"pack\"')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGC7gVHKsPKa"
   },
   "outputs": [],
   "source": [
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg9mqZ0vsPKa"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    textArr = text.split(' ')\n",
    "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
    "    return rem_text\n",
    "\n",
    "# remove stopwords from the text\n",
    "process_reviews_sampled['reviews']=process_reviews_sampled['reviews'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJo-NyoisPKa"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']):\n",
    "       output = []\n",
    "       for sent in texts:\n",
    "                doc = nlp(sent)\n",
    "                output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60XndWc6sPKa",
    "outputId": "ae689546-ffa3-45f4-a54b-a6cff2750f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fits maxpedition falcon ii holds water like accurate description amazon give low rating come dust cap already installedbuilt ini buy separately feel camelbak make money hate greedit holds water like\n",
      "['water', 'accurate', 'description', 'low', 'rating', 'dust', 'cap', 'ini', 'camelbak', 'money', 'hate', 'greedit', 'water']\n"
     ]
    }
   ],
   "source": [
    "text_list=process_reviews_sampled['reviews'].tolist()\n",
    "print(text_list[1])\n",
    "tokenized_reviews = lemmatization(text_list)\n",
    "print(tokenized_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLFvuSOpsPKa"
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMvfY6dNsPKa"
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=10,\n",
    "                random_state=100,\n",
    "                chunksize=1000,\n",
    "                passes=50,\n",
    "                iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3M5QoOTsPKa",
    "outputId": "6f8ddce5-7d3d-4cc6-ad77-086180bd258f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.032*\"easy\" + 0.030*\"gun\" + 0.020*\"scope\" + 0.019*\"holster\" + 0.019*\"good\" + 0.018*\"sight\" + 0.017*\"clean\" + 0.016*\"range\" + 0.015*\"rifle\" + 0.015*\"target\"'),\n",
       " (1,\n",
       "  '0.077*\"water\" + 0.049*\"bottle\" + 0.022*\"tire\" + 0.016*\"top\" + 0.015*\"room\" + 0.015*\"cap\" + 0.015*\"mile\" + 0.015*\"inch\" + 0.013*\"backpack\" + 0.013*\"tube\"'),\n",
       " (2,\n",
       "  '0.073*\"good\" + 0.062*\"great\" + 0.061*\"product\" + 0.055*\"price\" + 0.051*\"quality\" + 0.017*\"excellent\" + 0.015*\"nice\" + 0.012*\"strong\" + 0.012*\"high\" + 0.011*\"work\"'),\n",
       " (3,\n",
       "  '0.080*\"bike\" + 0.039*\"grip\" + 0.038*\"sturdy\" + 0.034*\"tool\" + 0.024*\"sharp\" + 0.022*\"solid\" + 0.017*\"seat\" + 0.017*\"kit\" + 0.016*\"bar\" + 0.016*\"clip\"'),\n",
       " (4,\n",
       "  '0.040*\"old\" + 0.037*\"year\" + 0.027*\"comfortable\" + 0.027*\"sock\" + 0.026*\"glove\" + 0.024*\"warm\" + 0.021*\"pair\" + 0.020*\"color\" + 0.017*\"son\" + 0.017*\"shirt\"'),\n",
       " (5,\n",
       "  '0.052*\"fit\" + 0.050*\"small\" + 0.049*\"size\" + 0.038*\"great\" + 0.035*\"perfect\" + 0.035*\"knife\" + 0.028*\"big\" + 0.027*\"large\" + 0.026*\"good\" + 0.024*\"little\"'),\n",
       " (6,\n",
       "  '0.090*\"bag\" + 0.049*\"weight\" + 0.043*\"heavy\" + 0.038*\"ball\" + 0.031*\"pack\" + 0.028*\"belt\" + 0.019*\"strap\" + 0.017*\"mat\" + 0.015*\"band\" + 0.013*\"glad\"'),\n",
       " (7,\n",
       "  '0.069*\"great\" + 0.041*\"light\" + 0.032*\"time\" + 0.024*\"good\" + 0.022*\"work\" + 0.019*\"use\" + 0.019*\"love\" + 0.018*\"easy\" + 0.017*\"day\" + 0.012*\"bright\"'),\n",
       " (8,\n",
       "  '0.032*\"camping\" + 0.028*\"value\" + 0.026*\"gift\" + 0.023*\"durable\" + 0.021*\"perfect\" + 0.019*\"car\" + 0.017*\"favorite\" + 0.016*\"workout\" + 0.015*\"lock\" + 0.014*\"handy\"'),\n",
       " (9,\n",
       "  '0.041*\"case\" + 0.027*\"great\" + 0.022*\"cool\" + 0.021*\"cold\" + 0.018*\"hot\" + 0.015*\"lightweight\" + 0.015*\"home\" + 0.015*\"dry\" + 0.014*\"stuff\" + 0.014*\"tent\"')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgOoe03hsPKa",
    "outputId": "df964632-78db-433e-c547-5d5dbe64cea9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-14.59201205 -14.5943555   -8.62420565 ... -13.61679534 -13.6716925\n",
      "  -13.51983232]\n",
      " [-14.5925232  -14.58750121 -14.40312398 ... -13.60918516 -13.67080549\n",
      "  -13.51383097]\n",
      " [ -5.9229034  -14.59494209 -14.41771546 ... -13.6171076  -13.6717497\n",
      "  -13.52049366]\n",
      " ...\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]\n",
      " [-14.57561075 -14.5950509  -14.39171327 ... -13.58607696 -13.67184984\n",
      "  -13.49984466]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-44e67b19412043eba8c7efbbf02f6c0e.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like B/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "LAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n",
      "/Users/jiaotianyu/opt/anaconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py:230: UserWarning: The memmapped array [[-4.10721849 -4.10956194  1.86058792 ... -3.13200178 -3.18689893\n",
      "  -3.03503876]\n",
      " [-0.54567349 -0.5406515  -0.35627427 ...  0.43766454  0.37604422\n",
      "   0.53301874]\n",
      " [ 1.72326522 -6.94877346 -6.77154683 ... -5.97093898 -6.02558108\n",
      "  -5.87432504]\n",
      " ...\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]\n",
      " [-0.514797   -0.53423716 -0.33089952 ...  0.47473679  0.3889639\n",
      "   0.56096908]] loaded from the file /var/folders/_k/g444wd2d479b_qz8598m36z80000gn/T/joblib_memmapping_folder_1302_98471dd8a7c840c69056a55848ff280b_2cfa14c8d27f4c109e89e11964267e07/1302-140573179045248-477ffcef2138481597cd8ddbac5dc52f.pkl is not not bytes aligned. This may cause segmentation faults if this memmapped array is used in some libraries like BLAS or PyTorch. To get rid of this warning, regenerate your pickle file with joblib >= 1.2.0. See https://github.com/joblib/joblib/issues/563 for more details\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el13021405731789042402823311253\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el13021405731789042402823311253_data = {\"mdsDat\": {\"x\": [0.2415350416699409, 0.22591172081609107, 0.1704999354780359, 0.11857464422036482, -0.044672871504102825, -0.149029901649849, -0.00705816910309583, -0.15475295561963004, -0.18229683393486754, -0.21871061037288778], \"y\": [0.03998565829708939, -0.020135589149499488, -0.14685936687473242, 0.1901813304795216, -0.1936166927656274, 0.22243521479429157, -0.02507367217867608, 0.06694997547315779, 0.0764949937953998, -0.21036185187092452], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.822422629804798, 16.570586333524457, 15.173951977503068, 9.950386984743592, 7.872309519583852, 7.314207654341061, 6.834248165155615, 6.710300993991247, 6.325209578533631, 5.426376162818683]}, \"tinfo\": {\"Term\": [\"product\", \"great\", \"price\", \"bag\", \"bike\", \"fit\", \"small\", \"good\", \"size\", \"quality\", \"water\", \"light\", \"perfect\", \"knife\", \"bottle\", \"weight\", \"year\", \"old\", \"big\", \"large\", \"heavy\", \"time\", \"case\", \"grip\", \"sturdy\", \"easy\", \"gun\", \"comfortable\", \"ball\", \"tool\", \"product\", \"price\", \"excellent\", \"strong\", \"line\", \"fast\", \"boat\", \"fishing\", \"rod\", \"service\", \"customer\", \"rail\", \"reel\", \"seller\", \"training\", \"idea\", \"fish\", \"ar\", \"foam\", \"comfort\", \"pool\", \"effective\", \"button\", \"bullet\", \"tree\", \"market\", \"everyday\", \"release\", \"roll\", \"strength\", \"quality\", \"decent\", \"high\", \"good\", \"cheap\", \"money\", \"great\", \"item\", \"job\", \"worth\", \"low\", \"plenty\", \"well\", \"happy\", \"star\", \"nice\", \"purchase\", \"work\", \"expensive\", \"use\", \"awesome\", \"bad\", \"little\", \"time\", \"brand\", \"easy\", \"one\", \"thing\", \"light\", \"bright\", \"week\", \"battery\", \"fun\", \"husband\", \"helmet\", \"goggle\", \"overall\", \"complaint\", \"protection\", \"useful\", \"arm\", \"chair\", \"change\", \"watch\", \"beautiful\", \"multiple\", \"safety\", \"cleaning\", \"cord\", \"match\", \"dark\", \"ear\", \"sleeve\", \"flashlight\", \"sling\", \"pole\", \"setup\", \"care\", \"time\", \"first\", \"day\", \"month\", \"couple\", \"night\", \"work\", \"last\", \"great\", \"love\", \"long\", \"wife\", \"second\", \"use\", \"easy\", \"thing\", \"good\", \"sure\", \"year\", \"little\", \"color\", \"star\", \"problem\", \"happy\", \"comfortable\", \"nice\", \"lot\", \"fit\", \"small\", \"size\", \"knife\", \"big\", \"large\", \"pocket\", \"tight\", \"blade\", \"head\", \"pant\", \"medium\", \"pad\", \"chain\", \"hat\", \"length\", \"leg\", \"adjustable\", \"golf\", \"waist\", \"sheath\", \"guy\", \"stock\", \"zipper\", \"compression\", \"man\", \"knee\", \"tiny\", \"saddle\", \"bed\", \"short\", \"perfect\", \"pouch\", \"little\", \"bit\", \"nice\", \"great\", \"comfortable\", \"good\", \"material\", \"love\", \"way\", \"quality\", \"hand\", \"star\", \"right\", \"gun\", \"scope\", \"holster\", \"sight\", \"clean\", \"range\", \"rifle\", \"target\", \"install\", \"pistol\", \"accurate\", \"glock\", \"rope\", \"thank\", \"equipment\", \"shot\", \"magazine\", \"bolt\", \"camp\", \"system\", \"barrel\", \"distance\", \"cable\", \"stove\", \"rock\", \"shoot\", \"laser\", \"block\", \"mag\", \"move\", \"easy\", \"screw\", \"speed\", \"red\", \"money\", \"good\", \"use\", \"simple\", \"work\", \"thing\", \"way\", \"well\", \"old\", \"sock\", \"glove\", \"warm\", \"pair\", \"shirt\", \"daughter\", \"amazing\", \"shoe\", \"pump\", \"rack\", \"emergency\", \"winter\", \"true\", \"feature\", \"jacket\", \"boy\", \"run\", \"finish\", \"satisfied\", \"wash\", \"paddle\", \"table\", \"plan\", \"ready\", \"coffee\", \"white\", \"board\", \"school\", \"touch\", \"year\", \"difference\", \"thick\", \"son\", \"color\", \"comfortable\", \"kid\", \"awesome\", \"hand\", \"soft\", \"love\", \"wear\", \"nice\", \"bike\", \"grip\", \"sturdy\", \"tool\", \"sharp\", \"seat\", \"kit\", \"bar\", \"clip\", \"ring\", \"friend\", \"compact\", \"road\", \"metal\", \"edge\", \"wheel\", \"frame\", \"key\", \"leather\", \"rear\", \"pedal\", \"tall\", \"tip\", \"vest\", \"sized\", \"ground\", \"truck\", \"slide\", \"stand\", \"brake\", \"solid\", \"front\", \"ride\", \"handle\", \"easy\", \"issue\", \"hand\", \"plastic\", \"case\", \"cool\", \"cold\", \"hot\", \"lightweight\", \"home\", \"tent\", \"cover\", \"weather\", \"space\", \"fan\", \"rain\", \"plate\", \"dog\", \"dot\", \"beach\", \"season\", \"degree\", \"oil\", \"bulky\", \"wonderful\", \"optic\", \"ruger\", \"local\", \"sun\", \"take\", \"roller\", \"functional\", \"snug\", \"sound\", \"dry\", \"store\", \"stuff\", \"great\", \"day\", \"easy\", \"help\", \"eye\", \"love\", \"adjustment\", \"use\", \"little\", \"lot\", \"water\", \"bottle\", \"tire\", \"cap\", \"mile\", \"inch\", \"backpack\", \"tube\", \"pleased\", \"mountain\", \"wide\", \"flat\", \"holder\", \"ice\", \"summer\", \"cup\", \"original\", \"swim\", \"trail\", \"drink\", \"leak\", \"hammock\", \"blue\", \"pound\", \"suit\", \"hike\", \"pressure\", \"daily\", \"lid\", \"feel\", \"room\", \"gear\", \"top\", \"foot\", \"air\", \"bag\", \"weight\", \"heavy\", \"ball\", \"pack\", \"belt\", \"mat\", \"band\", \"glad\", \"yoga\", \"gym\", \"towel\", \"duty\", \"phone\", \"smooth\", \"fantastic\", \"exercise\", \"wrist\", \"shoulder\", \"travel\", \"inexpensive\", \"sweat\", \"floor\", \"net\", \"loop\", \"tank\", \"height\", \"neck\", \"pot\", \"machine\", \"strap\", \"lot\", \"use\", \"solid\", \"nice\", \"enough\", \"camping\", \"value\", \"gift\", \"car\", \"favorite\", \"workout\", \"lock\", \"handy\", \"glass\", \"game\", \"storage\", \"pellet\", \"tape\", \"family\", \"condition\", \"weapon\", \"wind\", \"comfy\", \"basket\", \"outdoor\", \"team\", \"club\", \"pro\", \"load\", \"food\", \"face\", \"heat\", \"mask\", \"available\", \"basic\", \"durable\", \"yard\", \"perfect\", \"life\", \"item\", \"steel\"], \"Freq\": [14270.0, 40024.0, 13074.0, 7532.0, 7732.0, 10345.0, 10096.0, 30242.0, 9835.0, 13724.0, 6821.0, 9054.0, 8611.0, 7104.0, 4345.0, 4119.0, 5846.0, 4187.0, 5545.0, 5374.0, 3638.0, 9218.0, 3694.0, 3756.0, 3724.0, 12347.0, 3953.0, 7033.0, 3154.0, 3245.0, 14269.175165626812, 13073.271664501866, 3943.42001320155, 2800.5743127338324, 1783.0616347813668, 1584.4242974698475, 1105.8610533750677, 1017.2164239247893, 954.9698071822985, 950.3474537541804, 803.0729114296798, 722.3857991249499, 714.8797454467073, 679.386360752083, 669.819540778653, 660.2892309846902, 631.3467058294069, 630.6600948453224, 590.7913631848696, 585.4490729396797, 580.2964709201424, 569.926097583282, 559.0396954091107, 551.7038944624885, 547.9320360571157, 547.5788481104809, 547.0431092665102, 520.4067097929386, 490.11100209129904, 489.45167766239524, 12118.474580664837, 1043.5523967787456, 2715.7529853553337, 17163.43426945821, 2315.5897790599256, 2345.945385416902, 14717.734069722857, 2474.4790055595477, 1864.6459092555294, 1929.5479415470554, 1363.2782423579893, 942.1181142048096, 2434.914928013175, 1826.7438409615322, 2495.6889492163155, 3478.4918113183, 1330.3176209704004, 2586.505632380999, 1031.3175885779376, 2525.483890982737, 1327.7925440169367, 1200.3279858511096, 1762.052304952829, 1670.4797238168615, 1152.9469965270312, 1516.4244450786907, 1215.712661745736, 1173.6085737589601, 9053.552466683046, 2647.0665030469595, 1719.5577751307978, 1634.0349632917375, 1452.0314549733853, 1443.2342540979407, 1431.2200192916607, 1145.3158402291833, 1079.215292649269, 1067.1609355258674, 935.1283949349132, 879.6850698478432, 835.9920706872585, 750.2674731998756, 685.1263390427348, 640.1214013677203, 638.4918533658471, 630.2743331942609, 612.9185724516964, 593.7838514652552, 579.8941790876688, 538.6144403141578, 534.8975108978625, 528.9747728715698, 528.397287154526, 523.0179870265493, 510.78828618900974, 506.9857522869474, 492.5203808094917, 479.09854690063213, 6943.352173521771, 2357.581432704483, 3708.1000563107323, 1597.6330977745934, 1420.9321671381188, 1246.296770140331, 4853.1366737986245, 2045.6135718365229, 15235.353250253444, 4063.123553423781, 2509.86369653746, 1308.6639003797388, 1171.690291330641, 4228.282120372896, 3864.2201780196237, 2246.2549684281553, 5331.878203541562, 1433.1391524144383, 2035.9129552251777, 2560.995863335954, 1488.5033558837747, 1783.871092981627, 1438.2480607945865, 1496.6693193883218, 1663.3324221832918, 1801.2406872457436, 1429.0821021342992, 10344.110319219346, 10095.884878374594, 9834.286962771774, 7103.982870278627, 5544.167454692407, 5373.814990176497, 2954.0576427651863, 2498.397109520114, 2154.0304558565554, 1867.708980902718, 1793.0329085645571, 1355.0099440611436, 1307.0733989548933, 1304.7363009649816, 1237.1068609316967, 1207.608045441366, 1195.8243934497493, 1189.4707851618027, 1126.722803248572, 1028.1668041951382, 949.7283210163837, 937.6604665410945, 871.8933941647971, 836.36397024872, 795.5126678505551, 712.5559728511902, 591.639128055245, 555.4686125168703, 498.76960935439996, 444.4584212369046, 2945.150886507141, 7109.336347589492, 911.8141204042524, 4723.6143043264765, 2429.656568658392, 4596.342448927698, 7610.7375878038065, 2570.79582248253, 5295.965572737749, 1624.5025185245618, 2086.2810711566412, 1368.2462072999, 1604.8386982595082, 1286.6021257781686, 1272.6863942330529, 1227.7001326727695, 3952.328491060024, 2599.2316001943564, 2511.6719452909024, 2434.4747889084783, 2223.759862642776, 2056.4207642000115, 1958.5569730891248, 1917.3253472413849, 1614.5810220760131, 1308.3215936154143, 1067.5455392805818, 831.406530153948, 814.5407410985255, 738.8233023246141, 736.6427465133208, 735.1294950964701, 726.6512042523524, 724.1156314683244, 722.7838427071972, 718.8467774324617, 717.395076186674, 671.4339572642385, 665.3997722168718, 645.192802012941, 619.9110079438788, 589.8692522393459, 550.6985762429949, 538.3737062321985, 530.0518043187396, 526.2603383032418, 4276.830556476347, 878.292618180963, 668.8595784460643, 822.7283238637781, 1243.5158844208527, 2450.153652802596, 1448.0559307760511, 820.4410361323448, 1171.6060348646201, 1000.7547144593375, 831.6439029252186, 759.0301499186425, 4186.38403028292, 2775.6781224772826, 2726.6903474412284, 2549.6211870334896, 2230.6080544639967, 1747.7587950798986, 1472.8722974296668, 1269.0138539262327, 1098.1063605553643, 926.0453976829938, 856.7419700829296, 822.6165976768216, 808.4788602483704, 773.7528417104567, 770.0939153912304, 722.75170898889, 691.3199803345665, 637.554051739497, 615.7435255943832, 605.8483364896817, 573.5380949650903, 570.4668162987192, 569.3040344540881, 567.6787395673946, 550.6727034517073, 540.084035794635, 521.2722296423473, 512.0537374716698, 493.51868251674017, 460.3838136073811, 3809.359850199891, 781.2356004251477, 1342.389685580798, 1769.105983652569, 2041.665074545628, 2798.3090563516835, 1245.5324897163111, 1291.8192002271498, 1329.2337698291994, 902.2164696665056, 1444.4107697173374, 787.3310140208004, 1332.3536957880608, 7731.137537793024, 3755.2098607283306, 3723.3876095248443, 3244.2015601266567, 2321.844761255859, 1627.6808767570687, 1600.021031240563, 1569.6606330650263, 1533.1791984994636, 1455.5135247445153, 1441.4365650473223, 1422.6032655414356, 1325.225197679206, 1153.53245220458, 1013.6468166690325, 916.547239920019, 892.0055936057944, 803.3436667012099, 792.4671917682288, 689.3397695065566, 680.5815394389207, 656.162194885419, 583.822596075797, 578.4011221520437, 569.3488541372016, 527.2397360469023, 505.6940773008096, 493.84833612929066, 480.39532270290493, 469.46869233157275, 2086.2856217494264, 1136.8420922452754, 1163.310824961696, 738.002080908523, 1483.820839567605, 828.933214689662, 871.7821818247478, 605.4385986127846, 3693.5898745652253, 2018.063698845316, 1884.8665453872077, 1617.6195031668105, 1372.5754111625404, 1329.7585155154518, 1226.8911508864148, 1112.9944812219671, 973.0631947069631, 872.4965985201072, 753.4148838809685, 642.2308236625629, 619.9972201133603, 618.0487965766397, 588.3208320465344, 587.9330758043756, 566.3003702171502, 560.1121864963204, 517.4509154633071, 504.84549014811665, 488.94415782768914, 485.31236945165153, 484.3163887640605, 475.93493379794734, 460.94638026104894, 450.47662487294514, 448.62357193981774, 441.3388999681399, 437.1406565236081, 425.78919674731804, 1312.138238594102, 997.3024020488156, 1265.7804619145334, 2460.2629553446786, 1041.9824140172252, 1205.7877626756886, 509.637641920985, 537.9882696678067, 669.8342764156708, 514.4109301042685, 623.1287444093578, 617.5096263430808, 537.4582785916796, 6820.177029444368, 4344.37593207401, 1917.2499353331646, 1335.0704962930313, 1305.3754436507138, 1287.46592044413, 1168.404084216194, 1135.6852352328742, 1056.1748535896356, 1048.0912215009905, 1023.1527154354438, 1011.6097842623437, 969.3732117564618, 958.3631037614153, 920.9077180103085, 866.4258038878806, 834.0588629501532, 784.5970956980458, 699.4771873562487, 665.7799662043508, 650.3049835382728, 634.4115726145072, 614.903827929246, 602.7753204453178, 598.1888985874865, 556.7432096474151, 550.0682846482329, 511.5381985158796, 494.7350027646584, 493.03966756428264, 1338.1671382609525, 1016.2569383709944, 1429.1581064658305, 1030.3903956409938, 737.0902537095511, 7531.409926802071, 4118.357663816991, 3637.417877893535, 3153.907941972574, 2596.1543723869927, 2383.3575500679926, 1434.0857112358992, 1244.10442594595, 1129.7680578845814, 1071.8075746120348, 1052.99698535172, 1049.6781435518108, 1040.7910331240557, 987.8051493705785, 930.2086459769849, 900.9320374264249, 885.0024229510393, 822.7687223715642, 796.6937338354863, 749.1186019356869, 718.9882384399339, 681.1447749910875, 535.9028520258145, 526.2840796893505, 497.30282483285737, 445.6285546538899, 443.985618067511, 437.52676783648405, 397.35882132342044, 393.6297032745157, 1556.3156103894999, 867.813219862429, 1026.2796931363164, 688.7159461733944, 729.5342241875252, 524.1515628867738, 2262.7849416269473, 2024.706605206475, 1864.2691633924567, 1370.710207236724, 1241.1041109169196, 1118.133712464813, 1087.1299903409508, 991.9193837615869, 937.844005921367, 859.9684169898292, 839.0579549986428, 770.4775986300164, 745.3646372012721, 702.4148402016955, 658.4908277273416, 652.2073719407092, 598.3406112783414, 597.5800946819024, 575.327127659654, 572.9705559236866, 551.5322991589825, 544.3016077152855, 500.51720827534035, 499.5243041783806, 494.1924636722581, 486.32498835251175, 483.54228928498935, 462.28169144386, 442.62804765251224, 433.01601118297793, 1686.6970299129343, 619.800766160272, 1501.4069969556062, 576.8065042814416, 697.6638514340348, 539.2161628182607], \"Total\": [14270.0, 40024.0, 13074.0, 7532.0, 7732.0, 10345.0, 10096.0, 30242.0, 9835.0, 13724.0, 6821.0, 9054.0, 8611.0, 7104.0, 4345.0, 4119.0, 5846.0, 4187.0, 5545.0, 5374.0, 3638.0, 9218.0, 3694.0, 3756.0, 3724.0, 12347.0, 3953.0, 7033.0, 3154.0, 3245.0, 14270.089771162297, 13074.186257073568, 3944.334717157979, 2801.4889797472815, 1783.9762404207827, 1585.338969814546, 1106.7756377677522, 1018.131011844822, 955.8843695635836, 951.2620311497615, 803.9874720987516, 723.3003851222692, 715.7942608642919, 680.3009252708034, 670.7342010609433, 661.2038212304003, 632.261265076121, 631.574764380434, 591.7060191377426, 586.3637780923879, 581.2111617030853, 570.8407524084126, 559.9543158175702, 552.6185231640114, 548.8467717146071, 548.4935192502979, 547.9578477242668, 521.3213041457865, 491.02567370408065, 490.3663199690029, 13724.11796111111, 1144.261325898763, 3474.1763203641667, 30242.028672123848, 3090.4269241890306, 3590.268714170888, 40024.69551500173, 4003.571268637563, 3003.0850730139864, 3245.5789563103845, 1972.6438582262829, 1192.3508976100607, 5082.817374050362, 3892.0944286694407, 6669.674369916538, 12524.812309722825, 2332.0833828487707, 8611.95523843572, 1488.2074171037777, 10378.589448396022, 2620.4296158744887, 2087.779073711155, 10352.065984441435, 9218.619714464563, 2046.4052054098854, 12347.592002192117, 3265.5469737508756, 5823.406483768305, 9054.474932950228, 2647.9889181498943, 1720.4802293411901, 1634.9573655944055, 1452.9539175930915, 1444.1567837671957, 1432.1424388318221, 1146.2382581175034, 1080.1377863795324, 1068.0834059092283, 936.0508927263924, 880.6075653530078, 836.914569129187, 751.1899570997026, 686.048855090819, 641.0438144357887, 639.4144679672888, 631.196845098382, 613.8410593365347, 594.706441224167, 580.816666904993, 539.5369668748724, 535.8199469763466, 529.897223465114, 529.3197624081627, 523.9403951812511, 511.710751310806, 507.90817268171185, 493.4428437912309, 480.0210454827794, 9218.619714464563, 2815.8245973625703, 4750.908439668742, 1966.7657978413126, 1789.7373924288206, 1530.633941532409, 8611.95523843572, 2891.344746814708, 40024.69551500173, 8264.268899152139, 4288.118318113744, 1836.5856994354745, 1565.8063475801343, 10378.589448396022, 12347.592002192117, 5823.406483768305, 30242.028672123848, 2698.52185390479, 5846.098425085243, 10352.065984441435, 3530.9940440879436, 6669.674369916538, 3246.408766384034, 3892.0944286694407, 7033.152991427221, 12524.812309722825, 4737.341490105672, 10345.023411948658, 10096.797960849131, 9835.200031177164, 7104.895905309347, 5545.080559872443, 5374.72807065982, 2954.9707408591357, 2499.310154048372, 2154.943523515762, 1868.6221001409865, 1793.9459379157693, 1355.9230068391141, 1307.986488358787, 1305.6494559815078, 1238.0198914891425, 1208.5211410773782, 1196.7374638159515, 1190.3839865020057, 1127.6360238135005, 1029.0798317547205, 950.6413393750558, 938.5736607411603, 872.8065262692661, 837.2770452940624, 796.4257172408114, 713.4691191637013, 592.5521936061164, 556.3817641254603, 499.6827055306484, 445.371606672637, 3223.8451797702683, 8611.560136686023, 1049.274955953282, 10352.065984441435, 4573.452347639816, 12524.812309722825, 40024.69551500173, 7033.152991427221, 30242.028672123848, 2978.3467037154837, 8264.268899152139, 4257.787140129819, 13724.11796111111, 4013.146310908359, 6669.674369916538, 2977.0793544413064, 3953.2442719554274, 2600.1473712441657, 2512.5877209001874, 2435.3905468372845, 2224.6757332037423, 2057.3365797583997, 1959.4727572831118, 1918.2411172949546, 1615.4968449930077, 1309.2373827469437, 1068.4613570596932, 832.3223149623401, 815.4565788061715, 739.7393095905263, 737.558681211284, 736.0452835803733, 727.5670062187639, 725.0314710106481, 723.6997954825262, 719.7626493488426, 718.31085982766, 672.349815842914, 666.3156027905032, 646.1086373122724, 620.8269289633955, 590.785022417629, 551.6143288494868, 539.289586781644, 530.9675829520758, 527.176231084045, 12347.592002192117, 1249.6788978963982, 808.3440752866927, 1236.0525058542428, 3590.268714170888, 30242.028672123848, 10378.589448396022, 1663.4617512292682, 8611.95523843572, 5823.406483768305, 4257.787140129819, 5082.817374050362, 4187.3101509789785, 2776.604168969213, 2727.616423184727, 2550.5473050367054, 2231.53415492494, 1748.6848588391313, 1473.7984249832964, 1269.9400951611808, 1099.0324681878733, 926.9715196648818, 857.668190888873, 823.5427850022126, 809.4049934976944, 774.6790023622594, 771.020148725343, 723.6777967170735, 692.2460990186883, 638.4802020026851, 616.669746279072, 606.7745668426631, 574.4642255180137, 571.3929320353952, 570.2301810034553, 568.605007681795, 551.5989403346065, 541.0102569246955, 522.1983720138146, 512.9798387195666, 494.44483136220316, 461.3100347442193, 5846.098425085243, 885.3153139205652, 1831.7487418557598, 2663.728177255704, 3530.9940440879436, 7033.152991427221, 2089.5371959311515, 2620.4296158744887, 4013.146310908359, 1682.6827541283621, 8264.268899152139, 1537.7664530116883, 12524.812309722825, 7732.058377356395, 3756.1307033911407, 3724.3085102697287, 3245.122416874445, 2322.765645827439, 1628.6016842034041, 1600.9419330656776, 1570.581457554986, 1534.1000532936719, 1456.4343719399615, 1442.3575110277134, 1423.524183028394, 1326.146047992918, 1154.4533058461845, 1014.567666665673, 917.4680723477326, 892.9264378271087, 804.2645690559543, 793.3880722982395, 690.2606045408605, 681.5023453352234, 657.0831266669567, 584.7434553326638, 579.3219777282206, 570.2697927652802, 528.1606128013137, 506.61500354747295, 494.7692036053215, 481.31618876691635, 470.3894938158884, 2775.825873561116, 1632.5172178691253, 1787.5931170096067, 1404.2919241179884, 12347.592002192117, 2233.139758817581, 4013.146310908359, 2355.9613725173394, 3694.5163365495173, 2018.9901578589072, 1885.7930014532185, 1618.5459684920722, 1373.5019220152367, 1330.685062488573, 1227.8175632209134, 1113.920935973619, 973.9896229337157, 873.4230956500004, 754.3413523462563, 643.1572611848588, 620.9236958935492, 618.9752609886777, 589.247275155092, 588.8595525845885, 567.2268641939165, 561.0386498343629, 518.3773603774279, 505.7719415534893, 489.8706906714573, 486.23882741493287, 485.24289865479363, 476.86141296747167, 461.87281624867774, 451.40315907273714, 449.55009575093294, 442.2653577172229, 438.06715430627526, 426.71562583278444, 1657.8018583818312, 1375.6717484945943, 2111.1023543524107, 40024.69551500173, 4750.908439668742, 12347.592002192117, 711.524081187441, 999.9671537782452, 8264.268899152139, 869.5469543453272, 10378.589448396022, 10352.065984441435, 4737.341490105672, 6821.091738997978, 4345.290592574279, 1918.1646118791393, 1335.9851875874072, 1306.2902033090443, 1288.380680661812, 1169.3188588195724, 1136.5999526202122, 1057.089686470883, 1049.0060018594575, 1024.0674520132334, 1012.5245095297884, 970.2879215521536, 959.277820484065, 921.8225013032315, 867.3404863172156, 834.9735977658057, 785.511829720763, 700.3919421293064, 666.6946460269888, 651.2196748616668, 635.3263096168229, 615.8185981781294, 603.6900959838626, 599.1035890105125, 557.6579497220829, 550.9830306262741, 512.4529837632574, 495.6496722467871, 493.95449472360434, 2087.486241927395, 1421.3591412200951, 2570.6131878883707, 2129.4279377117996, 1209.06303907902, 7532.3362825925615, 4119.2840487801395, 3638.34427325374, 3154.8342797956257, 2597.0807629152723, 2384.2839012942754, 1435.012030990633, 1245.0307759568775, 1130.694532657363, 1072.7338869891553, 1053.9233610828403, 1050.604464034422, 1041.7173777515081, 988.7315376290031, 931.1350935012083, 901.8585848603612, 885.9287825200928, 823.6950877918695, 797.6200871548479, 750.0450145240401, 719.9146795810941, 682.0711414914233, 536.8292458529494, 527.2104378598717, 498.2291962211871, 446.55495036033295, 444.9120762215069, 438.4531453071227, 398.28520714202153, 394.55607968962397, 2936.5347066753407, 4737.341490105672, 10378.589448396022, 2775.825873561116, 12524.812309722825, 3250.0793139911157, 2263.7115319568343, 2025.633185940273, 1865.1957377181222, 1371.6368157543795, 1242.030743377844, 1119.0603279934874, 1088.0565715637774, 992.8459878343168, 938.7705715304877, 860.8949799459319, 839.9845790516015, 771.4041443032024, 746.2911975083198, 703.3414418392737, 659.4174253829203, 653.1339851175942, 599.2672040515287, 598.5067222340122, 576.2536625914767, 573.897154087398, 552.4589017256286, 545.2281680614248, 501.44381044204425, 500.4508907267066, 495.1190302444153, 487.2515385018386, 484.4688648383431, 463.2082064037431, 443.55469257995605, 433.9425781591437, 2366.7019027715455, 887.3045607695501, 8611.560136686023, 944.1315725118923, 4003.571268637563, 1246.0466113352882], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8049, -2.8924, -4.091, -4.4332, -4.8847, -5.0028, -5.3624, -5.4459, -5.5091, -5.5139, -5.6823, -5.7882, -5.7986, -5.8496, -5.8638, -5.8781, -5.9229, -5.924, -5.9893, -5.9984, -6.0072, -6.0253, -6.0445, -6.0577, -6.0646, -6.0653, -6.0662, -6.1161, -6.1761, -6.1775, -2.9683, -5.4204, -4.4639, -2.6202, -4.6233, -4.6103, -2.774, -4.557, -4.8399, -4.8057, -5.1531, -5.5226, -4.5731, -4.8605, -4.5484, -4.2164, -5.1776, -4.5127, -5.4322, -4.5366, -5.1795, -5.2804, -4.8965, -4.9499, -5.3207, -5.0466, -5.2677, -5.3029, -3.187, -4.4167, -4.8481, -4.8991, -5.0172, -5.0233, -5.0316, -5.2545, -5.3139, -5.3252, -5.4572, -5.5184, -5.5693, -5.6775, -5.7683, -5.8363, -5.8388, -5.8518, -5.8797, -5.9114, -5.9351, -6.0089, -6.0159, -6.027, -6.0281, -6.0383, -6.062, -6.0694, -6.0984, -6.126, -3.4524, -4.5325, -4.0797, -4.9217, -5.0389, -5.17, -3.8105, -4.6745, -2.6666, -3.9882, -4.4699, -5.1212, -5.2317, -3.9484, -4.0384, -4.5809, -3.7165, -5.0303, -4.6792, -4.4498, -4.9924, -4.8114, -5.0267, -4.9869, -4.8814, -4.8017, -5.0331, -2.9657, -2.99, -3.0163, -3.3415, -3.5894, -3.6206, -4.2189, -4.3865, -4.5348, -4.6774, -4.7182, -4.9983, -5.0343, -5.0361, -5.0894, -5.1135, -5.1233, -5.1286, -5.1828, -5.2743, -5.3537, -5.3665, -5.4392, -5.4808, -5.5309, -5.641, -5.827, -5.8901, -5.9977, -6.113, -4.222, -3.3407, -5.3944, -3.7496, -4.4144, -3.7769, -3.2726, -4.3579, -3.6352, -4.8169, -4.5667, -4.9886, -4.8291, -5.0501, -5.061, -5.097, -3.5059, -3.9249, -3.9592, -3.9904, -4.081, -4.1592, -4.2079, -4.2292, -4.4011, -4.6114, -4.8148, -5.0648, -5.0853, -5.1829, -5.1858, -5.1879, -5.1995, -5.203, -5.2048, -5.2103, -5.2123, -5.2785, -5.2875, -5.3184, -5.3583, -5.408, -5.4767, -5.4994, -5.5149, -5.5221, -3.4269, -5.0099, -5.2823, -5.0753, -4.6622, -3.984, -4.5099, -5.0781, -4.7218, -4.8794, -5.0645, -5.1559, -3.2141, -3.625, -3.6428, -3.71, -3.8436, -4.0876, -4.2587, -4.4077, -4.5523, -4.7227, -4.8005, -4.8412, -4.8585, -4.9024, -4.9071, -4.9706, -5.015, -5.096, -5.1308, -5.147, -5.2018, -5.2072, -5.2092, -5.2121, -5.2425, -5.2619, -5.2974, -5.3152, -5.3521, -5.4216, -3.3084, -4.8928, -4.3514, -4.0754, -3.9321, -3.6169, -4.4263, -4.3898, -4.3613, -4.7488, -4.2782, -4.885, -4.359, -2.5271, -3.2492, -3.2577, -3.3955, -3.73, -4.0852, -4.1023, -4.1215, -4.145, -4.197, -4.2067, -4.2199, -4.2908, -4.4295, -4.5588, -4.6595, -4.6866, -4.7913, -4.805, -4.9444, -4.9572, -4.9937, -5.1105, -5.1199, -5.1356, -5.2125, -5.2542, -5.2779, -5.3055, -5.3285, -3.837, -4.4441, -4.4211, -4.8762, -4.1777, -4.76, -4.7096, -5.0742, -3.1979, -3.8024, -3.8706, -4.0235, -4.1878, -4.2195, -4.3, -4.3974, -4.5318, -4.6409, -4.7876, -4.9473, -4.9825, -4.9857, -5.035, -5.0356, -5.0731, -5.0841, -5.1633, -5.188, -5.22, -5.2275, -5.2295, -5.247, -5.279, -5.3019, -5.3061, -5.3224, -5.332, -5.3583, -4.2328, -4.5072, -4.2688, -3.6042, -4.4634, -4.3174, -5.1785, -5.1244, -4.9052, -5.1692, -4.9775, -4.9866, -5.1254, -2.5663, -3.0173, -3.8353, -4.1972, -4.2197, -4.2335, -4.3306, -4.359, -4.4315, -4.4392, -4.4633, -4.4746, -4.5173, -4.5287, -4.5686, -4.6296, -4.6676, -4.7288, -4.8436, -4.893, -4.9165, -4.9412, -4.9725, -4.9924, -5.0, -5.0718, -5.0839, -5.1565, -5.1899, -5.1934, -4.1949, -4.4701, -4.1291, -4.4563, -4.7912, -2.408, -3.0116, -3.1358, -3.2784, -3.4731, -3.5586, -4.0666, -4.2087, -4.3051, -4.3577, -4.3754, -4.3786, -4.3871, -4.4394, -4.4994, -4.5314, -4.5493, -4.6222, -4.6544, -4.7159, -4.757, -4.8111, -5.0509, -5.069, -5.1256, -5.2354, -5.2391, -5.2537, -5.35, -5.3594, -3.9848, -4.5689, -4.4011, -4.8, -4.7424, -5.0731, -3.4572, -3.5684, -3.6509, -3.9585, -4.0578, -4.1622, -4.1903, -4.2819, -4.338, -4.4247, -4.4493, -4.5346, -4.5677, -4.627, -4.6916, -4.7012, -4.7874, -4.7887, -4.8266, -4.8307, -4.8689, -4.8821, -4.9659, -4.9679, -4.9786, -4.9947, -5.0004, -5.0454, -5.0888, -5.1108, -3.751, -4.7522, -3.8674, -4.8241, -4.6338, -4.8915], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7246, 1.7246, 1.7245, 1.7244, 1.7242, 1.7241, 1.7239, 1.7238, 1.7238, 1.7238, 1.7236, 1.7234, 1.7234, 1.7234, 1.7233, 1.7233, 1.7233, 1.7233, 1.7232, 1.7232, 1.7231, 1.7231, 1.7231, 1.7231, 1.723, 1.723, 1.723, 1.723, 1.7228, 1.7228, 1.6003, 1.6326, 1.4784, 1.1583, 1.4361, 1.2992, 0.7243, 1.2436, 1.2481, 1.2047, 1.3552, 1.4892, 0.9888, 0.9683, 0.7417, 0.4436, 1.1634, 0.5219, 1.358, 0.3114, 1.0449, 1.1712, -0.046, 0.0166, 1.1509, -0.3724, 0.7366, 0.1229, 1.7974, 1.7972, 1.797, 1.797, 1.7969, 1.7969, 1.7969, 1.7967, 1.7967, 1.7967, 1.7966, 1.7965, 1.7964, 1.7963, 1.7962, 1.7961, 1.7961, 1.7961, 1.796, 1.796, 1.796, 1.7958, 1.7958, 1.7958, 1.7958, 1.7958, 1.7957, 1.7957, 1.7957, 1.7956, 1.5141, 1.6199, 1.5497, 1.5897, 1.5668, 1.592, 1.224, 1.4515, 0.8317, 1.0876, 1.2619, 1.4586, 1.5076, 0.8996, 0.6358, 0.8449, 0.062, 1.1647, 0.7427, 0.4008, 0.9337, 0.4788, 0.9834, 0.8418, 0.3557, -0.1417, 0.5991, 1.8855, 1.8855, 1.8855, 1.8855, 1.8854, 1.8854, 1.8853, 1.8852, 1.8852, 1.8851, 1.8851, 1.8849, 1.8849, 1.8849, 1.8849, 1.8848, 1.8848, 1.8848, 1.8848, 1.8847, 1.8846, 1.8846, 1.8845, 1.8845, 1.8844, 1.8843, 1.884, 1.8839, 1.8838, 1.8835, 1.7952, 1.6939, 1.7452, 1.101, 1.2531, 0.8831, 0.2257, 0.8792, 0.1433, 1.2794, 0.509, 0.7504, -0.2605, 0.748, 0.2291, 0.9998, 2.3073, 2.3072, 2.3072, 2.3072, 2.3071, 2.3071, 2.3071, 2.3071, 2.307, 2.3069, 2.3067, 2.3065, 2.3064, 2.3063, 2.3063, 2.3063, 2.3063, 2.3063, 2.3063, 2.3063, 2.3063, 2.3062, 2.3062, 2.3061, 2.3061, 2.306, 2.3059, 2.3059, 2.3058, 2.3058, 1.2473, 1.9549, 2.1181, 1.9005, 1.2473, -0.2055, 0.338, 1.6007, 0.3128, 0.5464, 0.6745, 0.406, 2.5416, 2.5415, 2.5415, 2.5415, 2.5414, 2.5413, 2.5412, 2.5411, 2.541, 2.5408, 2.5407, 2.5407, 2.5407, 2.5406, 2.5406, 2.5405, 2.5405, 2.5404, 2.5403, 2.5403, 2.5402, 2.5402, 2.5402, 2.5402, 2.5401, 2.5401, 2.54, 2.54, 2.5399, 2.5398, 2.1135, 2.4168, 2.231, 2.1326, 1.994, 1.6202, 2.0244, 1.8345, 1.4368, 1.9185, 0.7976, 1.8724, 0.3011, 2.6152, 2.6151, 2.6151, 2.6151, 2.615, 2.6148, 2.6148, 2.6148, 2.6148, 2.6147, 2.6147, 2.6147, 2.6147, 2.6146, 2.6144, 2.6143, 2.6143, 2.6142, 2.6142, 2.614, 2.614, 2.6139, 2.6138, 2.6138, 2.6137, 2.6136, 2.6135, 2.6135, 2.6134, 2.6134, 2.3298, 2.2535, 2.1858, 1.972, 0.4965, 1.6243, 1.0886, 1.2566, 2.683, 2.6828, 2.6827, 2.6827, 2.6825, 2.6825, 2.6825, 2.6824, 2.6823, 2.6822, 2.682, 2.6818, 2.6817, 2.6817, 2.6817, 2.6816, 2.6816, 2.6816, 2.6814, 2.6814, 2.6813, 2.6813, 2.6813, 2.6813, 2.6812, 2.6812, 2.6812, 2.6811, 2.6811, 2.6811, 2.4494, 2.3616, 2.1717, -0.106, 1.166, 0.3569, 2.3495, 2.0633, 0.1706, 2.1583, -0.1295, -0.136, 0.5068, 2.7014, 2.7013, 2.701, 2.7008, 2.7008, 2.7008, 2.7007, 2.7007, 2.7007, 2.7007, 2.7006, 2.7006, 2.7006, 2.7006, 2.7005, 2.7005, 2.7004, 2.7004, 2.7002, 2.7002, 2.7001, 2.7001, 2.7, 2.7, 2.7, 2.6999, 2.6999, 2.6997, 2.6997, 2.6997, 2.2569, 2.366, 2.1145, 1.9756, 2.2066, 2.7605, 2.7604, 2.7604, 2.7603, 2.7603, 2.7602, 2.76, 2.7599, 2.7598, 2.7598, 2.7597, 2.7597, 2.7597, 2.7597, 2.7596, 2.7596, 2.7596, 2.7595, 2.7595, 2.7594, 2.7593, 2.7593, 2.7589, 2.7589, 2.7588, 2.7586, 2.7585, 2.7585, 2.7583, 2.7583, 2.1257, 1.0634, 0.4468, 1.3668, -0.0824, 0.936, 2.9135, 2.9134, 2.9134, 2.9132, 2.9132, 2.9131, 2.913, 2.913, 2.9129, 2.9128, 2.9128, 2.9127, 2.9127, 2.9126, 2.9125, 2.9125, 2.9124, 2.9123, 2.9123, 2.9123, 2.9122, 2.9122, 2.912, 2.912, 2.912, 2.912, 2.912, 2.9119, 2.9118, 2.9118, 2.5752, 2.5551, 1.1672, 2.4211, 1.1667, 2.0763]}, \"token.table\": {\"Topic\": [4, 3, 1, 7, 5, 7, 8, 5, 1, 2, 10, 1, 5, 8, 1, 2, 3, 4, 9, 9, 9, 6, 4, 10, 10, 2, 7, 2, 3, 9, 3, 6, 2, 3, 5, 7, 3, 4, 8, 5, 1, 4, 8, 5, 6, 1, 2, 3, 5, 8, 2, 7, 1, 1, 4, 4, 10, 8, 10, 2, 7, 3, 2, 2, 1, 4, 6, 4, 2, 6, 10, 5, 7, 2, 5, 1, 2, 3, 5, 10, 6, 2, 3, 10, 7, 2, 1, 2, 7, 8, 1, 8, 2, 5, 2, 7, 1, 5, 7, 5, 10, 4, 7, 7, 8, 5, 7, 5, 10, 9, 2, 1, 2, 4, 6, 7, 6, 1, 5, 1, 2, 4, 5, 6, 7, 8, 9, 10, 4, 1, 1, 9, 1, 2, 4, 2, 7, 10, 10, 7, 9, 1, 10, 5, 8, 5, 1, 2, 1, 1, 3, 2, 8, 9, 1, 10, 3, 8, 9, 6, 6, 4, 6, 2, 7, 10, 4, 8, 10, 9, 10, 4, 5, 2, 3, 1, 2, 3, 4, 1, 2, 3, 7, 6, 6, 4, 3, 9, 8, 1, 3, 5, 6, 1, 3, 6, 10, 1, 2, 3, 10, 3, 3, 10, 9, 9, 2, 4, 7, 1, 4, 5, 8, 8, 4, 7, 7, 2, 8, 1, 8, 9, 4, 4, 5, 6, 10, 1, 3, 10, 5, 1, 2, 4, 6, 2, 5, 6, 3, 3, 3, 4, 1, 2, 5, 8, 6, 3, 3, 8, 1, 10, 2, 7, 1, 1, 2, 3, 4, 7, 10, 7, 10, 2, 3, 5, 7, 8, 9, 1, 2, 4, 5, 7, 8, 9, 10, 2, 3, 5, 7, 1, 3, 6, 9, 4, 4, 3, 1, 10, 9, 2, 1, 3, 9, 3, 6, 8, 1, 4, 1, 2, 8, 4, 2, 9, 9, 1, 2, 3, 4, 5, 9, 2, 7, 7, 5, 1, 2, 3, 5, 7, 8, 10, 2, 9, 3, 5, 5, 3, 6, 10, 3, 10, 9, 4, 5, 1, 4, 6, 7, 8, 7, 8, 1, 4, 3, 2, 1, 9, 3, 7, 8, 8, 1, 10, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 1, 3, 5, 1, 7, 4, 5, 6, 2, 4, 1, 1, 2, 6, 4, 1, 2, 3, 4, 6, 6, 6, 4, 1, 1, 7, 2, 8, 4, 7, 5, 3, 2, 5, 5, 4, 4, 6, 7, 6, 1, 2, 1, 1, 2, 6, 3, 5, 5, 4, 2, 3, 4, 9, 4, 1, 4, 9, 3, 6, 2, 6, 2, 3, 9, 7, 5, 5, 6, 9, 6, 9, 2, 5, 7, 7, 2, 4, 6, 1, 2, 3, 4, 5, 8, 9, 1, 6, 10, 3, 10, 5, 6, 7, 4, 2, 3, 9, 1, 1, 1, 7, 6, 8, 8, 7, 2, 3, 7, 8, 10, 9, 8, 4, 5, 7, 6, 9, 10, 4, 10, 7, 4, 5, 6, 1, 2, 3, 4, 7, 3, 1, 2, 4, 3, 6, 8, 6, 2, 3, 8, 5, 9, 8, 1, 9, 1, 6, 5, 8, 1, 2, 4, 6, 7, 9, 2, 10, 6, 3, 5, 5, 2, 8, 1, 2, 3, 4, 6, 8, 10, 3, 5, 7, 2, 9, 1, 2, 3, 4, 5, 6, 6, 5, 8, 2, 3, 10, 5, 7, 1, 2, 4, 10, 1, 2, 4, 9, 7, 10, 2, 5, 9, 3], \"Freq\": [0.9995682042624706, 0.9988373612903912, 0.4071085502984976, 0.5911124148401914, 0.23737389261242872, 0.15218395902678358, 0.6095629228409755, 0.9992597326718301, 0.999089950370329, 0.9989072132772898, 0.9987494381431754, 0.5067871283223992, 0.4930489230365511, 0.9988721136158671, 0.5747734590839282, 0.19398604244082576, 0.12309731582047462, 0.1072910456956666, 0.9998225938749377, 0.9997355551126826, 0.9991720879702067, 0.9996297819815783, 0.9981750800371102, 0.9978278735330783, 0.9978244605234459, 0.9994144400248276, 0.9985403096870623, 0.9977878699370294, 0.9969203095749991, 0.9994615149254757, 0.999805131799119, 0.9998631182920845, 0.31223677245416936, 0.5313272808568849, 0.07849649951753977, 0.07784053991154362, 0.9995621585877004, 0.9976087304237786, 0.9986707154013355, 0.9980899079347595, 0.9992991915061334, 0.9985773431197265, 0.9997029905027561, 0.9981999190454743, 0.9970460781242868, 0.5634270265497392, 0.14220057651862456, 0.13096135569412845, 0.13487064989395317, 0.0278537211737512, 0.9996265399212527, 0.9984737359072979, 0.9988807411657682, 0.998295725578654, 0.9980255560803416, 0.9990330307029318, 0.9996856790510674, 0.9992625759652424, 0.9995357256767498, 0.9978729151723911, 0.9998602424505721, 0.9995025801308824, 0.9984159038756363, 0.9984711655984323, 0.7494110221058695, 0.13849219234080837, 0.11195864147177498, 0.9996962554166179, 0.9988121177522261, 0.9992829324975838, 0.9977474236780695, 0.998132647372643, 0.9995794864799014, 0.42169428251885055, 0.5783074042333733, 0.9976741774588727, 0.23645156049172353, 0.36555439688768565, 0.3978301059866762, 0.9991533558184263, 0.9996317709002465, 0.9989856542071206, 0.9994654652259519, 0.9978504884336393, 0.9995095776692853, 0.9985939334190516, 0.20561675783093172, 0.7939712306460706, 0.9991732483483543, 0.9984544866308417, 0.9987717817341434, 0.9991160481495671, 0.9984697341318224, 0.999458253605268, 0.7804823113489724, 0.21932647476419342, 0.9123789962751625, 0.08739262416428759, 0.9981487018146262, 0.8821715695184226, 0.11634272939871641, 0.9979923905516033, 0.9984243942364999, 0.9978832737838903, 0.9989580746881224, 0.2081068966449055, 0.7914094156467131, 0.2868971369841092, 0.7128062887955703, 0.9993113508838102, 0.9983067971950355, 0.12277697544030111, 0.31293550996129516, 0.34638332714918724, 0.12018537701412062, 0.09767086568667753, 0.999440484174369, 0.9985271682078313, 0.9993409146287268, 0.07569046051922672, 0.2812239061568017, 0.09138238526101762, 0.06430612296145685, 0.16707284578024434, 0.09015164606558304, 0.047691143823090004, 0.16122683460193007, 0.02123025112124652, 0.9992425264246548, 0.9982519682339712, 0.999661611588851, 0.9989516284622215, 0.6927797752859236, 0.1659714883565695, 0.14043741322478956, 0.46101514260560633, 0.5380176718477575, 0.9974314324266954, 0.9980927587093891, 0.9982218231281048, 0.999047982827048, 0.9991554047178297, 0.9991701144409351, 0.9986768844795697, 0.998067646445573, 0.9989139303766511, 0.1622970409549114, 0.8374101150365013, 0.9980051520695813, 0.9988891293638403, 0.9999010720509849, 0.9982051485438037, 0.9994819784362238, 0.9984552893506541, 0.998806807578582, 0.9977398763205226, 0.3911848742320482, 0.4836979837443092, 0.12444656863324462, 0.9989624701567096, 0.9990588248632296, 0.30321272852858994, 0.6964704491656702, 0.9993434632843196, 0.9971389174052562, 0.998960407521498, 0.2842349890916424, 0.7148087844482889, 0.9993589210537307, 0.9993857468685812, 0.9991791694862874, 0.9984112945927686, 0.9997740066456972, 0.9989197201290969, 0.9994359671027984, 0.5675214512252716, 0.17631092337779808, 0.17512052704591496, 0.0810130836976004, 0.36772297229552986, 0.38063999748079885, 0.19015759900402757, 0.06146205407304005, 0.9996989712338498, 0.9978025381424072, 0.9996852529543255, 0.9993887951844852, 0.9991238821370355, 0.9979123962021614, 0.13082004973827344, 0.32069600764411027, 0.33116161162317215, 0.21728587308909414, 0.31759778172912656, 0.15595048026609576, 0.5255317554172542, 0.9991479163488769, 0.46941307141527444, 0.38462581713665345, 0.11921601813721255, 0.026720831651444194, 0.9991761913551197, 0.9996670808180319, 0.9990322085228335, 0.9996305260984722, 0.9979499854684709, 0.9992022868669725, 0.2824921957167735, 0.7167712428634551, 0.7817680363774128, 0.12895142868081036, 0.0892297832389536, 0.9988201553973887, 0.9986726398179899, 0.9997660894004621, 0.99948518059766, 0.9996626796503155, 0.9991989901787685, 0.9986679349227315, 0.9981793492539711, 0.998928359697925, 0.9987294611333299, 0.9996924506571786, 0.2897266046360566, 0.22345220357556758, 0.3712262059401714, 0.11553240184869025, 0.6179482851673864, 0.2075646826896112, 0.1743443423794809, 0.9990633998719481, 0.6210280277302401, 0.2504091564896196, 0.12820149634109515, 0.9984276703157039, 0.40343861867667663, 0.5963042928483263, 0.9994116382073434, 0.9990681097596553, 0.9998739031055083, 0.9998645381403024, 0.9988863073032056, 0.17638851284055593, 0.7076292103368185, 0.1158630427482083, 0.9981270915042211, 0.9982504497525169, 0.9993837714300344, 0.9995687778561213, 0.9986892511320705, 0.3887170079733535, 0.6111436337891688, 0.9999475471572074, 0.9996345676644557, 0.999452772745139, 0.17020757041620344, 0.24739023146191658, 0.45633403101370323, 0.06636356462879216, 0.05969822844336761, 0.9990990310236998, 0.9981935779577736, 0.9990289369216723, 0.5853383264629922, 0.2574555826355153, 0.04780651670315276, 0.08745094518869406, 0.02192103692729931, 0.9975328699511993, 0.1868136383767975, 0.3016459765428741, 0.08570207591071162, 0.05741616908303832, 0.11335471616761611, 0.03820708310305124, 0.1832251278091076, 0.033563128250746664, 0.49163453532070306, 0.2524119223920715, 0.1747280996808012, 0.08107190220646593, 0.6909508750482469, 0.1977042122295057, 0.11101851917503013, 0.9985906193865739, 0.9981776986333211, 0.9992206817874951, 0.9993424814738286, 0.999100227745676, 0.9973916558751769, 0.9992947578356298, 0.9990047635141988, 0.35053004363045154, 0.5456047135052526, 0.10374883475269112, 0.9993192778391852, 0.9996073415495551, 0.9990123149467278, 0.6534329842054091, 0.34649217065282556, 0.1871092127003176, 0.812501418193227, 0.9990409951347521, 0.9977688085791989, 0.9981038480979805, 0.9989664909193312, 0.9977040707600834, 0.27768879197495683, 0.14379456996748052, 0.3669516066466077, 0.04678712826260054, 0.10634889905423878, 0.05828430653873447, 0.8140417941814063, 0.1855440365549915, 0.9973429387880192, 0.9996871139390828, 0.3723725335370929, 0.40115791030722997, 0.07686308052451506, 0.14974520468720265, 0.9974522244109566, 0.9988339777827576, 0.998436733688243, 0.9989466284821439, 0.9995838547146069, 0.9992457962161178, 0.9975622168961149, 0.9997606333186695, 0.9994727054501608, 0.9992628853903999, 0.9981797553026232, 0.8255182437517935, 0.17430058853164185, 0.9992601251187381, 0.9990548828170889, 0.998935978977284, 0.3476287894843116, 0.12309200116050105, 0.2567953817313901, 0.0691861937557299, 0.20288957432661897, 0.9985123842113645, 0.9989691636529717, 0.7900358878314578, 0.20883114232487582, 0.9996714888422708, 0.9982119352856309, 0.9979161417004858, 0.9967731486910001, 0.8691716073328315, 0.13056634890855034, 0.9988568704564583, 0.9982158604319326, 0.9999092672346681, 0.9991149348485266, 0.25566712627026433, 0.44295099708028934, 0.14693158943483867, 0.1543243738089186, 0.999923632494275, 0.9988773124041028, 0.9989519422719341, 0.5703055087058381, 0.2980167883838778, 0.1312131471157793, 0.8829711340530421, 0.11694740635048131, 0.9992209214519422, 0.9982021506568819, 0.9982006559597464, 0.9993503349079825, 0.9989141742472472, 0.9981737266583554, 0.334128200900797, 0.6658293204391185, 0.9988903782724762, 0.9974654706506738, 0.34851331327690044, 0.6505954788780661, 0.9997587324032168, 0.24856576258071297, 0.15888054824415843, 0.4124848060123183, 0.08834161561990204, 0.0917006124115333, 0.9997017565993153, 0.9991358055964857, 0.9986680201440742, 0.9990748153314952, 0.9979111607416707, 0.9987763415998966, 0.35880475998176714, 0.6409623082184305, 0.99944009427597, 0.9974386051640545, 0.9992478983668109, 0.9986337219137426, 0.9986298418397691, 0.9987234685087518, 0.9991003417692169, 0.9995587283794546, 0.7025804800560764, 0.29687626207380907, 0.9978370837642536, 0.9996305516510021, 0.250988891830308, 0.7484961354328779, 0.9980877208563467, 0.9986733086064246, 0.9991025428845447, 0.9996703731911937, 0.9993253613655414, 0.9996083577691718, 0.9990605662546297, 0.9986712215309446, 0.08623242882271732, 0.9135054060536062, 0.9985798651201341, 0.9992225783116123, 0.9994290251150517, 0.4857340419176471, 0.4929479138273151, 0.020439303744059407, 0.9998779860934845, 0.9977733473149212, 0.997506682157193, 0.9984453284486657, 0.9986110291624998, 0.9999209689198273, 0.9987809572325964, 0.997563948139492, 0.9997824072383219, 0.5360487577275018, 0.17293812472140027, 0.29060736422255923, 0.7514880597765535, 0.24821441667595656, 0.33561983074453194, 0.6641068015515403, 0.9983229443932646, 0.9983706686288834, 0.17195647775447767, 0.8276178677535652, 0.9972654384007147, 0.374231163556975, 0.26747932523463275, 0.190863890708345, 0.0679193578090183, 0.04363031594354155, 0.03103599793922028, 0.025038703651448245, 0.26965283396576617, 0.29693913264087346, 0.4325680878200832, 0.9990759392316719, 0.9988278605629723, 0.11485298013345141, 0.159194953476113, 0.724736842993994, 0.9982841317260759, 0.2577868391199958, 0.21215482268395952, 0.529876250555764, 0.9972136749336918, 0.9998254571940791, 0.400264818168519, 0.5996866979897575, 0.9996486568537165, 0.9981579329004936, 0.9991077443845549, 0.9981102671168943, 0.5310314600292874, 0.23123770485573994, 0.06633261084804078, 0.07744980819687443, 0.09375503097516379, 0.9984295751186876, 0.9993484124600072, 0.9989404154973412, 0.997842658904356, 0.9968915612473349, 0.9983516139389382, 0.9987572629977898, 0.9982698475975186, 0.9993529920280799, 0.9991693468524171, 0.9993341329808244, 0.9990005809060822, 0.7326332314771559, 0.26695801057550617, 0.201600215144231, 0.38568490904083713, 0.1780744660175192, 0.1718925173418869, 0.062849811535595, 0.9994757937320224, 0.18115510257784803, 0.7531496270646699, 0.06551957003414384, 0.9975165179476502, 0.9987285786170265, 0.9993928509201312, 0.9996541218696069, 0.15054773772397123, 0.29292621836214555, 0.5558984940763692, 0.9971601858933208, 0.9994246511840422, 0.9980126240101013, 0.998905377033433, 0.9986067309244057, 0.9984571801124714, 0.99878605342683, 0.9991235048837145, 0.9994721514647004, 0.24328932294265004, 0.40737713164416806, 0.13951799588948802, 0.05077761314486201, 0.06002742502703801, 0.09885736449075602, 0.9993100611703646, 0.9996874133260316, 0.99771806045853, 0.9989506822295028, 0.9997854166297466, 0.9991918982986363, 0.9983716956434445, 0.9998399465892335, 0.20268744575467137, 0.2106728144170802, 0.32129365676986144, 0.195406668444828, 0.04157088980136365, 0.028183654102619426, 0.9982637787292755, 0.4877203547594229, 0.511781225594221, 0.9989839492019074, 0.9997208748272719, 0.9996882835063244, 0.47906501863151013, 0.13161991682319518, 0.05823541910263943, 0.14932663209088962, 0.09463255604178906, 0.08695964609245482, 0.9994898216495591, 0.9977051402722816, 0.9989576350550593, 0.7127355943163216, 0.2869454990104671, 0.9978854106432634, 0.9982641650237134, 0.9982226112154947, 0.3003963592906347, 0.5635189530875339, 0.1360898852294642, 0.9990524836177612, 0.5946550757138408, 0.24556481624037882, 0.15990983642253023, 0.9991561345913416, 0.3009113350757869, 0.6987454222733628, 0.3482664594327819, 0.6515456502846101, 0.9993158722791772, 0.9984747637580176], \"Term\": [\"accurate\", \"adjustable\", \"adjustment\", \"adjustment\", \"air\", \"air\", \"air\", \"amazing\", \"ar\", \"arm\", \"available\", \"awesome\", \"awesome\", \"backpack\", \"bad\", \"bad\", \"bad\", \"bad\", \"bag\", \"ball\", \"band\", \"bar\", \"barrel\", \"basic\", \"basket\", \"battery\", \"beach\", \"beautiful\", \"bed\", \"belt\", \"big\", \"bike\", \"bit\", \"bit\", \"bit\", \"bit\", \"blade\", \"block\", \"blue\", \"board\", \"boat\", \"bolt\", \"bottle\", \"boy\", \"brake\", \"brand\", \"brand\", \"brand\", \"brand\", \"brand\", \"bright\", \"bulky\", \"bullet\", \"button\", \"cable\", \"camp\", \"camping\", \"cap\", \"car\", \"care\", \"case\", \"chain\", \"chair\", \"change\", \"cheap\", \"cheap\", \"cheap\", \"clean\", \"cleaning\", \"clip\", \"club\", \"coffee\", \"cold\", \"color\", \"color\", \"comfort\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfy\", \"compact\", \"complaint\", \"compression\", \"condition\", \"cool\", \"cord\", \"couple\", \"couple\", \"cover\", \"cup\", \"customer\", \"daily\", \"dark\", \"daughter\", \"day\", \"day\", \"decent\", \"decent\", \"degree\", \"difference\", \"difference\", \"distance\", \"dog\", \"dot\", \"drink\", \"dry\", \"dry\", \"durable\", \"durable\", \"duty\", \"ear\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"edge\", \"effective\", \"emergency\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"equipment\", \"everyday\", \"excellent\", \"exercise\", \"expensive\", \"expensive\", \"expensive\", \"eye\", \"eye\", \"face\", \"family\", \"fan\", \"fantastic\", \"fast\", \"favorite\", \"feature\", \"feel\", \"finish\", \"first\", \"first\", \"fish\", \"fishing\", \"fit\", \"flashlight\", \"flat\", \"floor\", \"foam\", \"food\", \"foot\", \"foot\", \"foot\", \"frame\", \"friend\", \"front\", \"front\", \"fun\", \"functional\", \"game\", \"gear\", \"gear\", \"gift\", \"glad\", \"glass\", \"glock\", \"glove\", \"goggle\", \"golf\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"grip\", \"ground\", \"gun\", \"guy\", \"gym\", \"hammock\", \"hand\", \"hand\", \"hand\", \"hand\", \"handle\", \"handle\", \"handle\", \"handy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hat\", \"head\", \"heat\", \"heavy\", \"height\", \"helmet\", \"help\", \"help\", \"high\", \"high\", \"high\", \"hike\", \"holder\", \"holster\", \"home\", \"hot\", \"husband\", \"ice\", \"idea\", \"inch\", \"inexpensive\", \"install\", \"issue\", \"issue\", \"issue\", \"issue\", \"item\", \"item\", \"item\", \"jacket\", \"job\", \"job\", \"job\", \"key\", \"kid\", \"kid\", \"kit\", \"knee\", \"knife\", \"large\", \"laser\", \"last\", \"last\", \"last\", \"leak\", \"leather\", \"leg\", \"length\", \"lid\", \"life\", \"life\", \"light\", \"lightweight\", \"line\", \"little\", \"little\", \"little\", \"little\", \"little\", \"load\", \"local\", \"lock\", \"long\", \"long\", \"long\", \"long\", \"long\", \"loop\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"low\", \"low\", \"low\", \"machine\", \"mag\", \"magazine\", \"man\", \"market\", \"mask\", \"mat\", \"match\", \"material\", \"material\", \"material\", \"medium\", \"metal\", \"mile\", \"money\", \"money\", \"month\", \"month\", \"mountain\", \"move\", \"multiple\", \"neck\", \"net\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"oil\", \"old\", \"one\", \"one\", \"one\", \"one\", \"optic\", \"original\", \"outdoor\", \"overall\", \"pack\", \"pad\", \"paddle\", \"pair\", \"pant\", \"pedal\", \"pellet\", \"perfect\", \"perfect\", \"phone\", \"pistol\", \"plan\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plastic\", \"plate\", \"pleased\", \"plenty\", \"plenty\", \"pocket\", \"pole\", \"pool\", \"pot\", \"pouch\", \"pouch\", \"pound\", \"pressure\", \"price\", \"pro\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"protection\", \"pump\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"rack\", \"rail\", \"rain\", \"range\", \"ready\", \"rear\", \"red\", \"red\", \"reel\", \"release\", \"ride\", \"ride\", \"rifle\", \"right\", \"right\", \"right\", \"right\", \"right\", \"ring\", \"road\", \"rock\", \"rod\", \"roll\", \"roller\", \"room\", \"room\", \"rope\", \"ruger\", \"run\", \"saddle\", \"safety\", \"satisfied\", \"school\", \"scope\", \"screw\", \"screw\", \"season\", \"seat\", \"second\", \"second\", \"seller\", \"service\", \"setup\", \"sharp\", \"sheath\", \"shirt\", \"shoe\", \"shoot\", \"short\", \"short\", \"shot\", \"shoulder\", \"sight\", \"simple\", \"simple\", \"simple\", \"size\", \"sized\", \"sleeve\", \"slide\", \"sling\", \"small\", \"smooth\", \"snug\", \"sock\", \"soft\", \"soft\", \"soft\", \"solid\", \"solid\", \"son\", \"son\", \"sound\", \"space\", \"speed\", \"speed\", \"stand\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"steel\", \"steel\", \"steel\", \"stock\", \"storage\", \"store\", \"store\", \"store\", \"stove\", \"strap\", \"strap\", \"strap\", \"strength\", \"strong\", \"stuff\", \"stuff\", \"sturdy\", \"suit\", \"summer\", \"sun\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweat\", \"swim\", \"system\", \"table\", \"take\", \"tall\", \"tank\", \"tape\", \"target\", \"team\", \"tent\", \"thank\", \"thick\", \"thick\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"tight\", \"time\", \"time\", \"time\", \"tiny\", \"tip\", \"tire\", \"tool\", \"top\", \"top\", \"top\", \"touch\", \"towel\", \"trail\", \"training\", \"travel\", \"tree\", \"truck\", \"true\", \"tube\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"useful\", \"value\", \"vest\", \"waist\", \"warm\", \"wash\", \"watch\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"weapon\", \"wear\", \"wear\", \"weather\", \"week\", \"weight\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wheel\", \"white\", \"wide\", \"wife\", \"wife\", \"wind\", \"winter\", \"wonderful\", \"work\", \"work\", \"work\", \"workout\", \"worth\", \"worth\", \"worth\", \"wrist\", \"yard\", \"yard\", \"year\", \"year\", \"yoga\", \"zipper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 8, 6, 1, 5, 4, 10, 2, 7, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el13021405731789042402823311253\", ldavis_el13021405731789042402823311253_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el13021405731789042402823311253\", ldavis_el13021405731789042402823311253_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el13021405731789042402823311253\", ldavis_el13021405731789042402823311253_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.241535  0.039986       1        1  17.822423\n",
       "7      0.225912 -0.020136       2        1  16.570586\n",
       "5      0.170500 -0.146859       3        1  15.173952\n",
       "0      0.118575  0.190181       4        1   9.950387\n",
       "4     -0.044673 -0.193617       5        1   7.872310\n",
       "3     -0.149030  0.222435       6        1   7.314208\n",
       "9     -0.007058 -0.025074       7        1   6.834248\n",
       "1     -0.154753  0.066950       8        1   6.710301\n",
       "6     -0.182297  0.076495       9        1   6.325210\n",
       "8     -0.218711 -0.210362      10        1   5.426376, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "55    product  14270.000000  14270.000000  Default  30.0000  30.0000\n",
       "103     great  40024.000000  40024.000000  Default  29.0000  29.0000\n",
       "122     price  13074.000000  13074.000000  Default  28.0000  28.0000\n",
       "31        bag   7532.000000   7532.000000  Default  27.0000  27.0000\n",
       "418      bike   7732.000000   7732.000000  Default  26.0000  26.0000\n",
       "...       ...           ...           ...      ...      ...      ...\n",
       "101      yard    619.800766    887.304561  Topic10  -4.7522   2.5551\n",
       "436   perfect   1501.406997   8611.560137  Topic10  -3.8674   1.1672\n",
       "1059     life    576.806504    944.131573  Topic10  -4.8241   2.4211\n",
       "659      item    697.663851   4003.571269  Topic10  -4.6338   1.1667\n",
       "723     steel    539.216163   1246.046611  Topic10  -4.8915   2.0763\n",
       "\n",
       "[464 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "6         4  0.999568    accurate\n",
       "2309      3  0.998837  adjustable\n",
       "473       1  0.407109  adjustment\n",
       "473       7  0.591112  adjustment\n",
       "117       5  0.237374         air\n",
       "...     ...       ...         ...\n",
       "101      10  0.698745        yard\n",
       "416       2  0.348266        year\n",
       "416       5  0.651546        year\n",
       "597       9  0.999316        yoga\n",
       "691       3  0.998475      zipper\n",
       "\n",
       "[570 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 8, 6, 1, 5, 4, 10, 2, 7, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkim86rYsPKa"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLqlddm6sPKa"
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "# import libraries\n",
    "import nltk\n",
    "import re, random, os\n",
    "import string, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# spacy for basic preprocessing, optional, can use nltk as well (lemmatisation etc.)\n",
    "import spacy\n",
    "\n",
    "# gensim for LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "!pip install pyLDAvis\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "#from pyLDAvis import gensim_models as pg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK9NEeRdsPKa"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=process_reviews_short_reviews['review_processed'].tolist(), vector_size=200, sg=1,min_count=5,window=5,workers=90,seed=10,epochs=128)\n",
    "model.wv.vectors.shape\n",
    "#vector_size (int, optional)  Dimensionality of the word vectors.\n",
    "#min_count (int, optional)  Ignores all words with total frequency lower than this.\n",
    "#window (int, optional)  Maximum distance between the current and predicted word within a sentence.\n",
    "#workers (int, optional)  Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "#sg ({0, 1}, optional)  Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "#epochs (int, optional)  Number of iterations (epochs) over the corpus. (Formerly: iter)\n",
    "\n",
    "#The meaning of most of the parameters are beyond the scope of this class. If interested, please check the official documentations: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpryBxJVsPKa"
   },
   "outputs": [],
   "source": [
    "model.save('w2v_dr.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QArAnfURsPKa"
   },
   "outputs": [],
   "source": [
    "model=Word2Vec.load('w2v_dr.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Om_QzGwssPKa"
   },
   "outputs": [],
   "source": [
    "vocab = model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TW4ubPiWsPKb"
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iDfAhANsPKb"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('footwear','use', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3dN4C9hsPKb"
   },
   "outputs": [],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak_285-HsPKb"
   },
   "outputs": [],
   "source": [
    "outdata=pd.DataFrame(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHaaORZzsPKb"
   },
   "outputs": [],
   "source": [
    "outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGcmjd28sPKb"
   },
   "outputs": [],
   "source": [
    "outdata.to_csv('social.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AcltyiusPKb"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model.wv.index_to_key).to_csv('social project.tsv',sep='\\t',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
